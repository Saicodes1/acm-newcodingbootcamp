
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A template site, replace this with the actual description">
      
      
        <meta name="author" content="ACM BPDC">
      
      
        <link rel="canonical" href="https://Saicodes1.github.io/acm-newcodingbootcamp/day4/day4/">
      
      
        <link rel="prev" href="../../day3/day3/">
      
      
      
      <link rel="icon" href="../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.23">
    
    
      
        <title>DL with CNN and Image Detection - ML Workshop</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#welcome-to-day-4-of-the-bootcamp" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="ML Workshop" class="md-header__button md-logo" aria-label="ML Workshop" data-md-component="logo">
      
  <img src="../../assets/ACM_Logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ML Workshop
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              DL with CNN and Image Detection
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/Saicodes1/acm-newcodingbootcamp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    Saicodes1/acm-newcodingbootcamp
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../day1/day1/" class="md-tabs__link">
        
  
  
    
  
  Data Cleaning and Feature Engineering

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../day2/day2/" class="md-tabs__link">
        
  
  
    
  
  Model Training and Analysis

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../day3/day3/" class="md-tabs__link">
        
  
  
    
  
  Deep Learning & NLP

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
  
    
  
  DL with CNN and Image Detection

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="ML Workshop" class="md-nav__button md-logo" aria-label="ML Workshop" data-md-component="logo">
      
  <img src="../../assets/ACM_Logo.png" alt="logo">

    </a>
    ML Workshop
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Saicodes1/acm-newcodingbootcamp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    Saicodes1/acm-newcodingbootcamp
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../day1/day1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Data Cleaning and Feature Engineering
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../day2/day2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Model Training and Analysis
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../day3/day3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Deep Learning & NLP
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    DL with CNN and Image Detection
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    DL with CNN and Image Detection
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#welcome-to-day-4-of-the-bootcamp" class="md-nav__link">
    <span class="md-ellipsis">
      Welcome to Day 4 of the Bootcamp!!!
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-recap" class="md-nav__link">
    <span class="md-ellipsis">
      1. Recap
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Recap">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-what-are-anns" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 What are ANN's?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-key-terms" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 Key Terms
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-major-applications-of-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      2. Major Applications of CNNs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Major Applications of CNNs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-differences-in-applications-anns-vs-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Differences in Applications: ANNs vs. CNNs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-problems-solved-by-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      3. Problems Solved by CNNs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Problems Solved by CNNs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-image-classification" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Image Classification
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.1 Image Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#popular-models" class="md-nav__link">
    <span class="md-ellipsis">
      Popular Models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#32-image-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 Image Segmentation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.2 Image Segmentation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#popular-models_1" class="md-nav__link">
    <span class="md-ellipsis">
      Popular Models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#33-object-detection" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 Object Detection
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.3 Object Detection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#popular-models_2" class="md-nav__link">
    <span class="md-ellipsis">
      Popular Models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-convolutional-neural-networks-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      4. Convolutional Neural Networks (CNNs)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Convolutional Neural Networks (CNNs)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-conversion-of-images-to-pixel-values-for-both-grayscale-and-rgb" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 Conversion of Images to Pixel Values for Both Grayscale and RGB
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.1 Conversion of Images to Pixel Values for Both Grayscale and RGB">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#grayscale-images" class="md-nav__link">
    <span class="md-ellipsis">
      Grayscale Images
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rgb-images" class="md-nav__link">
    <span class="md-ellipsis">
      RGB Images
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-images-are-stored-and-processed" class="md-nav__link">
    <span class="md-ellipsis">
      How Images Are Stored and Processed
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-in-python" class="md-nav__link">
    <span class="md-ellipsis">
      Example in Python
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      Key Takeaways
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#41-what-are-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 What are CNN's?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-how-cnns-work" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 How CNNs Work?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.2 How CNNs Work?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#421-convolution-layer" class="md-nav__link">
    <span class="md-ellipsis">
      4.2.1 Convolution Layer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.2.1 Convolution Layer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Example Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stride" class="md-nav__link">
    <span class="md-ellipsis">
      Stride
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kernel-filter" class="md-nav__link">
    <span class="md-ellipsis">
      Kernel (Filter)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#padding" class="md-nav__link">
    <span class="md-ellipsis">
      Padding
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#422-pooling-layer" class="md-nav__link">
    <span class="md-ellipsis">
      4.2.2 Pooling Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#423-flattening-layers" class="md-nav__link">
    <span class="md-ellipsis">
      4.2.3 Flattening Layers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#424-fully-connected-layer" class="md-nav__link">
    <span class="md-ellipsis">
      4.2.4 Fully Connected Layer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-intuition-behind-finding-edges-and-textures-using-cnn-using-mnist-dataset-for-1-layer" class="md-nav__link">
    <span class="md-ellipsis">
      5. Intuition behind finding edges and textures using CNN using MNIST Dataset for 1 layer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Intuition behind finding edges and textures using CNN using MNIST Dataset for 1 layer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-input-image" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 Input Image
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-first-convolution-layer-conv1-detecting-simple-edges" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 First Convolution Layer (Conv1) – Detecting Simple Edges
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-tensors-parallelism-and-training-in-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      6. Tensors, Parallelism, and Training in CNNs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Tensors, Parallelism, and Training in CNNs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-what-are-tensors" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 What Are Tensors?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62-why-gpus-and-tpus-are-essential" class="md-nav__link">
    <span class="md-ellipsis">
      6.2 Why GPUs and TPUs Are Essential
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6.2 Why GPUs and TPUs Are Essential">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#621-the-role-of-gpus" class="md-nav__link">
    <span class="md-ellipsis">
      6.2.1 The Role of GPUs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#622-the-role-of-tpus" class="md-nav__link">
    <span class="md-ellipsis">
      6.2.2 The Role of TPUs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#623-why-parallelism-matters" class="md-nav__link">
    <span class="md-ellipsis">
      6.2.3 Why Parallelism Matters
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63-the-training-cycle-in-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      6.3 The Training Cycle in CNNs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6.3 The Training Cycle in CNNs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#631-forward-propagation" class="md-nav__link">
    <span class="md-ellipsis">
      6.3.1 Forward Propagation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#632-loss-calculation" class="md-nav__link">
    <span class="md-ellipsis">
      6.3.2 Loss Calculation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#633-backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      6.3.3 Backpropagation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#634-weight-updates" class="md-nav__link">
    <span class="md-ellipsis">
      6.3.4 Weight Updates
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#635-epochs-and-iterations" class="md-nav__link">
    <span class="md-ellipsis">
      6.3.5 Epochs and Iterations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#64-how-cnn-training-differs-from-rnn-training" class="md-nav__link">
    <span class="md-ellipsis">
      6.4 How CNN Training Differs from RNN Training
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6.4 How CNN Training Differs from RNN Training">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#641-data-structure" class="md-nav__link">
    <span class="md-ellipsis">
      6.4.1 Data Structure
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#642-backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      6.4.2 Backpropagation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#643-epochs" class="md-nav__link">
    <span class="md-ellipsis">
      6.4.3 Epochs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#644-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      6.4.4 Parallelism
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#65-summary" class="md-nav__link">
    <span class="md-ellipsis">
      6.5 Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-advantages-and-disadvantages-of-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      7. Advantages and Disadvantages of CNN
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Advantages and Disadvantages of CNN">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71-advantages" class="md-nav__link">
    <span class="md-ellipsis">
      7.1 Advantages
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7.1 Advantages">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#711-cnns-for-videos" class="md-nav__link">
    <span class="md-ellipsis">
      7.1.1 CNNs for Videos
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-disadvantages" class="md-nav__link">
    <span class="md-ellipsis">
      7.2 Disadvantages
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#welcome-to-day-4-of-the-bootcamp" class="md-nav__link">
    <span class="md-ellipsis">
      Welcome to Day 4 of the Bootcamp!!!
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-recap" class="md-nav__link">
    <span class="md-ellipsis">
      1. Recap
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Recap">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-what-are-anns" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 What are ANN's?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-key-terms" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 Key Terms
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-major-applications-of-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      2. Major Applications of CNNs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Major Applications of CNNs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-differences-in-applications-anns-vs-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Differences in Applications: ANNs vs. CNNs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-problems-solved-by-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      3. Problems Solved by CNNs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Problems Solved by CNNs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-image-classification" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Image Classification
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.1 Image Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#popular-models" class="md-nav__link">
    <span class="md-ellipsis">
      Popular Models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#32-image-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 Image Segmentation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.2 Image Segmentation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#popular-models_1" class="md-nav__link">
    <span class="md-ellipsis">
      Popular Models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#33-object-detection" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 Object Detection
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.3 Object Detection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#popular-models_2" class="md-nav__link">
    <span class="md-ellipsis">
      Popular Models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-convolutional-neural-networks-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      4. Convolutional Neural Networks (CNNs)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Convolutional Neural Networks (CNNs)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-conversion-of-images-to-pixel-values-for-both-grayscale-and-rgb" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 Conversion of Images to Pixel Values for Both Grayscale and RGB
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.1 Conversion of Images to Pixel Values for Both Grayscale and RGB">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#grayscale-images" class="md-nav__link">
    <span class="md-ellipsis">
      Grayscale Images
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rgb-images" class="md-nav__link">
    <span class="md-ellipsis">
      RGB Images
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-images-are-stored-and-processed" class="md-nav__link">
    <span class="md-ellipsis">
      How Images Are Stored and Processed
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-in-python" class="md-nav__link">
    <span class="md-ellipsis">
      Example in Python
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      Key Takeaways
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#41-what-are-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 What are CNN's?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-how-cnns-work" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 How CNNs Work?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.2 How CNNs Work?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#421-convolution-layer" class="md-nav__link">
    <span class="md-ellipsis">
      4.2.1 Convolution Layer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.2.1 Convolution Layer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Example Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stride" class="md-nav__link">
    <span class="md-ellipsis">
      Stride
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kernel-filter" class="md-nav__link">
    <span class="md-ellipsis">
      Kernel (Filter)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#padding" class="md-nav__link">
    <span class="md-ellipsis">
      Padding
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#422-pooling-layer" class="md-nav__link">
    <span class="md-ellipsis">
      4.2.2 Pooling Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#423-flattening-layers" class="md-nav__link">
    <span class="md-ellipsis">
      4.2.3 Flattening Layers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#424-fully-connected-layer" class="md-nav__link">
    <span class="md-ellipsis">
      4.2.4 Fully Connected Layer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-intuition-behind-finding-edges-and-textures-using-cnn-using-mnist-dataset-for-1-layer" class="md-nav__link">
    <span class="md-ellipsis">
      5. Intuition behind finding edges and textures using CNN using MNIST Dataset for 1 layer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Intuition behind finding edges and textures using CNN using MNIST Dataset for 1 layer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-input-image" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 Input Image
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-first-convolution-layer-conv1-detecting-simple-edges" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 First Convolution Layer (Conv1) – Detecting Simple Edges
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-tensors-parallelism-and-training-in-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      6. Tensors, Parallelism, and Training in CNNs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Tensors, Parallelism, and Training in CNNs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-what-are-tensors" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 What Are Tensors?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62-why-gpus-and-tpus-are-essential" class="md-nav__link">
    <span class="md-ellipsis">
      6.2 Why GPUs and TPUs Are Essential
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6.2 Why GPUs and TPUs Are Essential">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#621-the-role-of-gpus" class="md-nav__link">
    <span class="md-ellipsis">
      6.2.1 The Role of GPUs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#622-the-role-of-tpus" class="md-nav__link">
    <span class="md-ellipsis">
      6.2.2 The Role of TPUs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#623-why-parallelism-matters" class="md-nav__link">
    <span class="md-ellipsis">
      6.2.3 Why Parallelism Matters
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63-the-training-cycle-in-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      6.3 The Training Cycle in CNNs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6.3 The Training Cycle in CNNs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#631-forward-propagation" class="md-nav__link">
    <span class="md-ellipsis">
      6.3.1 Forward Propagation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#632-loss-calculation" class="md-nav__link">
    <span class="md-ellipsis">
      6.3.2 Loss Calculation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#633-backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      6.3.3 Backpropagation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#634-weight-updates" class="md-nav__link">
    <span class="md-ellipsis">
      6.3.4 Weight Updates
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#635-epochs-and-iterations" class="md-nav__link">
    <span class="md-ellipsis">
      6.3.5 Epochs and Iterations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#64-how-cnn-training-differs-from-rnn-training" class="md-nav__link">
    <span class="md-ellipsis">
      6.4 How CNN Training Differs from RNN Training
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6.4 How CNN Training Differs from RNN Training">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#641-data-structure" class="md-nav__link">
    <span class="md-ellipsis">
      6.4.1 Data Structure
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#642-backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      6.4.2 Backpropagation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#643-epochs" class="md-nav__link">
    <span class="md-ellipsis">
      6.4.3 Epochs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#644-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      6.4.4 Parallelism
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#65-summary" class="md-nav__link">
    <span class="md-ellipsis">
      6.5 Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-advantages-and-disadvantages-of-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      7. Advantages and Disadvantages of CNN
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Advantages and Disadvantages of CNN">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71-advantages" class="md-nav__link">
    <span class="md-ellipsis">
      7.1 Advantages
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7.1 Advantages">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#711-cnns-for-videos" class="md-nav__link">
    <span class="md-ellipsis">
      7.1.1 CNNs for Videos
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-disadvantages" class="md-nav__link">
    <span class="md-ellipsis">
      7.2 Disadvantages
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


  <h1>DL with CNN and Image Detection</h1>

<h2 id="welcome-to-day-4-of-the-bootcamp"><strong>Welcome to Day 4 of the Bootcamp!!!</strong><a class="headerlink" href="#welcome-to-day-4-of-the-bootcamp" title="Permanent link">&para;</a></h2>
<p>Today, we'll be learning how <strong>image recognition</strong> happens, and how <strong>Deep Learning (DL)</strong> works!
CNN_Model_Training colab link: <a href="https://colab.research.google.com/drive/11mLrtD7BT0J9wWm1ugqtHlw1g81FfiAl?usp=sharing">CNN_Model_Training</a></p>
<hr />
<h2 id="1-recap"><strong>1. Recap</strong><a class="headerlink" href="#1-recap" title="Permanent link">&para;</a></h2>
<h3 id="11-what-are-anns"><strong>1.1 What are ANN's?</strong><a class="headerlink" href="#11-what-are-anns" title="Permanent link">&para;</a></h3>
<p>An <strong>Artificial Neural Network (ANN)</strong> is a type of model in Deep Learning that tries to work like the human brain — it learns by finding patterns in data.</p>
<ul>
<li>Just like our brain has neurons that send signals to each other, an ANN has <strong>artificial neurons (nodes)</strong> connected in layers that pass information forward and adjust themselves to learn.</li>
<li>ANN is made up of layers of neurons:</li>
<li><strong>Input Layer</strong>: Receives the data.</li>
<li><strong>Hidden Layers</strong>: Where the actual learning happens — the model adjusts its weights and biases for each neuron during training.</li>
<li><strong>Output Layer</strong>: Produces the final prediction.</li>
</ul>
<p><img alt="Example of an ANN" src="../../assets/ANN.png" /></p>
<pre><code class="language-python"># Define the model
model = Sequential([
    Input(shape=(4,)),            # Input layer (4 features)
    Dense(4, activation='relu'),  # Hidden layer 1
    Dense(4, activation='relu'),  # Hidden layer 2
    Dense(3, activation='sigmoid') # Output layer (multi-class classification)
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
</code></pre>
<h3 id="12-key-terms"><strong>1.2 Key Terms</strong><a class="headerlink" href="#12-key-terms" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Activation Function</strong>: Adds non-linearity (mathematically) for a neuron, so the model can learn complex patterns instead of simple linear ones.</li>
<li>
<p><strong>ReLU (Rectified Linear Unit)</strong>: The most commonly used activation function in deep learning. It outputs the input directly if it is positive; otherwise, it outputs zero.<br />
<strong>Formula</strong>: <code>f(x) = max(0, x)</code><br />
<strong>Advantages</strong>:  </p>
<ul>
<li>Computationally efficient.  </li>
<li>Helps mitigate the vanishing gradient problem (After a point of time, the network stops learning ).<br />
<strong>Disadvantages</strong>:  </li>
<li>Can suffer from the "dying ReLU" problem, where neurons output zero for all inputs.
<img alt="Relu Activation Function" src="../../assets/Relu-activation-function.png" /></li>
</ul>
</li>
<li>
<p><strong>Sigmoid</strong>: Maps input values to a range between 0 and 1, making it useful for binary classification tasks.<br />
<strong>Formula</strong>: <code>f(x) = 1 / (1 + e^(-x))</code><br />
<strong>Advantages</strong>:  </p>
<ul>
<li>Outputs can be interpreted as probabilities.<br />
<strong>Disadvantages</strong>:  </li>
<li>Can cause vanishing gradients for very large or small input values.<br />
<img alt="Sigmoid Activation Function" src="../../assets/sigmoid_function.jpg" /></li>
</ul>
</li>
<li>
<p><strong>Tanh (Hyperbolic Tangent)</strong>: Similar to Sigmoid but maps inputs to a range between -1 and 1.<br />
<strong>Formula</strong>: <code>f(x) = (e^x - e^(-x)) / (e^x + e^(-x))</code><br />
<strong>Advantages</strong>:  </p>
<ul>
<li>Helps with optimization.<br />
<strong>Disadvantages</strong>:  </li>
<li>Can still suffer from vanishing gradients.
<img alt="TanH Activation Function" src="../../assets/tanh.jpg" /></li>
</ul>
</li>
<li>
<p><strong>Softmax</strong>: Converts raw scores (logits) into probabilities for multi-class classification tasks.<br />
<strong>Formula</strong>: <code>f(xᵢ) = e^(xᵢ) / Σ(e^(xⱼ))</code> (for all <code>j</code>)<br />
<strong>Advantages</strong>:  </p>
<ul>
<li>Ensures the output probabilities sum to 1.<br />
<strong>Disadvantages</strong>:  </li>
<li>Not suitable for hidden layers, only used in the output layer for multi-class classification.
<img alt="softmax" src="../../assets/softmax.jpg" /></li>
</ul>
</li>
<li>
<p><strong>Optimizers</strong>: Algorithms that improve model learning by adjusting weights and biases during training to reduce error.</p>
</li>
<li><strong>Loss Function</strong>: Measures how wrong the model’s predictions are — the model tries to minimize this loss while learning.</li>
</ul>
<hr />
<h2 id="2-major-applications-of-cnns"><strong>2. Major Applications of CNNs</strong><a class="headerlink" href="#2-major-applications-of-cnns" title="Permanent link">&para;</a></h2>
<p>CNNs are widely used in various fields due to their ability to process grid-like data such as images. Here are some key applications:</p>
<ul>
<li><strong>Image Classification</strong>: Assigning a label to an entire image (e.g., identifying cats, dogs, or cars).</li>
<li><strong>Image Segmentation</strong>: Dividing an image into regions and labeling each pixel (e.g., tumor segmentation in medical imaging).</li>
<li><strong>Object Detection</strong>: Identifying and localizing multiple objects in an image (e.g., detecting pedestrians in autonomous vehicles).</li>
<li><strong>Facial Recognition</strong>: Identifying or verifying individuals based on facial features.</li>
<li><strong>Medical Imaging</strong>: Diagnosing diseases from X-rays, MRIs, or CT scans.</li>
<li><strong>Autonomous Vehicles</strong>: Recognizing traffic signs, lanes, and obstacles.</li>
<li><strong>Satellite Imagery</strong>: Land cover classification, disaster monitoring, and urban planning.</li>
<li><strong>Video Analysis</strong>: Action recognition, surveillance, and video classification.</li>
</ul>
<hr />
<h3 id="21-differences-in-applications-anns-vs-cnns"><strong>2.1 Differences in Applications: ANNs vs. CNNs</strong><a class="headerlink" href="#21-differences-in-applications-anns-vs-cnns" title="Permanent link">&para;</a></h3>
<p>Here are the key differences between ANN and CNN applications:</p>
<ol>
<li>
<p><strong>Image Classification</strong>
   <strong>ANN</strong>: Can be used for simple image classification tasks but requires manual feature extraction.<br />
<strong>CNN</strong>: Automatically extracts features like edges, textures, and shapes, making it ideal for complex image classification tasks.</p>
</li>
<li>
<p><strong>Image Segmentation</strong>
   <strong>ANN</strong>: Not suitable for pixel-level tasks like segmentation due to its fully connected structure.<br />
<strong>CNN</strong>: Perfect for tasks like semantic and instance segmentation, as it processes spatial relationships in images.</p>
</li>
<li>
<p><strong>Object Detection</strong>
   <strong>ANN</strong>: Struggles with detecting and localizing multiple objects in an image.<br />
<strong>CNN</strong>: Excels at object detection tasks, using architectures like YOLO and Faster R-CNN.</p>
</li>
<li>
<p><strong>Tabular Data</strong>
   <strong>ANN</strong>: Works well for structured data like spreadsheets, where relationships between features are not spatial.<br />
<strong>CNN</strong>: Not typically used for tabular data, as it is designed for grid-like data such as images.</p>
</li>
<li>
<p><strong>Video Analysis</strong> 
   <strong>ANN</strong>: Limited in handling sequential frames in videos.<br />
<strong>CNN</strong>: Can process video data by extending its architecture to 3D CNNs for spatiotemporal analysis.</p>
</li>
</ol>
<hr />
<h2 id="3-problems-solved-by-cnns"><strong>3. Problems Solved by CNNs</strong><a class="headerlink" href="#3-problems-solved-by-cnns" title="Permanent link">&para;</a></h2>
<p>CNNs are the backbone of modern computer vision, solving problems like image classification, segmentation, and object detection. Below are the details of these problems and popular models used for each:</p>
<h3 id="31-image-classification"><strong>3.1 Image Classification</strong><a class="headerlink" href="#31-image-classification" title="Permanent link">&para;</a></h3>
<p>Image classification involves assigning a single label to an entire image. For example, determining whether an image contains a cat, dog, or car.</p>
<h4 id="popular-models"><strong>Popular Models</strong><a class="headerlink" href="#popular-models" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>AlexNet</strong>: Introduced ReLU activation and dropout, revolutionizing deep learning in 2012.</li>
<li><strong>VGGNet</strong>: Known for its simplicity and use of small (3×3) convolution filters.</li>
<li><strong>ResNet</strong>: Introduced residual connections, enabling the training of very deep networks.</li>
<li><strong>EfficientNet</strong>: Balances model size, accuracy, and computational efficiency.</li>
</ul>
<h2 id="_1"><img alt="classification" src="../../assets/image_classification.jpg" /><a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<h3 id="32-image-segmentation"><strong>3.2 Image Segmentation</strong><a class="headerlink" href="#32-image-segmentation" title="Permanent link">&para;</a></h3>
<p>Image segmentation involves dividing an image into regions, where each pixel is assigned a label. It is more detailed than classification.</p>
<h4 id="popular-models_1"><strong>Popular Models</strong><a class="headerlink" href="#popular-models_1" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>U-Net</strong>: Designed for biomedical image segmentation, uses an encoder-decoder structure.</li>
<li><strong>Mask R-CNN</strong>: Extends Faster R-CNN for instance segmentation.</li>
</ul>
<h2 id="_2"><img alt="segmentation" src="../../assets/segmented_image.jpg" /><a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<h3 id="33-object-detection"><strong>3.3 Object Detection</strong><a class="headerlink" href="#33-object-detection" title="Permanent link">&para;</a></h3>
<p>Object detection identifies and localizes multiple objects in an image by drawing bounding boxes around them.</p>
<h4 id="popular-models_2"><strong>Popular Models</strong><a class="headerlink" href="#popular-models_2" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>YOLO (You Only Look Once)</strong>: Real-time object detection with high speed and accuracy.</li>
<li><strong>SSD (Single Shot MultiBox Detector)</strong>: Balances speed and accuracy for real-time applications.</li>
<li><strong>Faster R-CNN</strong>: Combines region proposal networks with CNNs for high accuracy.</li>
</ul>
<h2 id="_3"><img alt="segmentation" src="../../assets/object_detection.jpg" /><a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<h2 id="4-convolutional-neural-networks-cnns"><strong>4. Convolutional Neural Networks (CNNs)</strong><a class="headerlink" href="#4-convolutional-neural-networks-cnns" title="Permanent link">&para;</a></h2>
<h3 id="41-conversion-of-images-to-pixel-values-for-both-grayscale-and-rgb"><strong>4.1 Conversion of Images to Pixel Values for Both Grayscale and RGB</strong><a class="headerlink" href="#41-conversion-of-images-to-pixel-values-for-both-grayscale-and-rgb" title="Permanent link">&para;</a></h3>
<p>Images are essentially grids of pixels, where each pixel represents a small part of the image. These pixels are stored as numerical values that describe the intensity of light or color at that point. Computers process these numerical values to analyze and understand images.</p>
<hr />
<h4 id="grayscale-images"><strong>Grayscale Images</strong><a class="headerlink" href="#grayscale-images" title="Permanent link">&para;</a></h4>
<p>A grayscale image contains only shades of gray, ranging from black to white. Each pixel in a grayscale image is represented by a single value, typically between 0 and 255:
- <strong>0</strong> represents black (no light).
- <strong>255</strong> represents white (maximum light).
- Values in between (e.g., 128) represent shades of gray.</p>
<p><strong>Example</strong>:<br />
A 3×3 grayscale image might look like this:</p>
<table>
<thead>
<tr>
<th><strong>Pixel</strong></th>
<th><strong>Value</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Black</td>
<td>0</td>
</tr>
<tr>
<td>Dark Gray</td>
<td>50</td>
</tr>
<tr>
<td>Light Gray</td>
<td>200</td>
</tr>
</tbody>
</table>
<p><strong>Matrix Representation</strong>:</p>
<pre><code>[[  0, 128, 255 ],
 [ 64, 200,  50 ],
 [128, 255,   0 ]]
</code></pre>
<hr />
<h4 id="rgb-images"><strong>RGB Images</strong><a class="headerlink" href="#rgb-images" title="Permanent link">&para;</a></h4>
<p>An RGB image contains three color channels: <strong>Red</strong>, <strong>Green</strong>, and <strong>Blue</strong>. Each pixel is represented by three values, one for each channel, typically between 0 and 255:
- <strong>(255, 0, 0)</strong> represents pure red.</p>
<ul>
<li>
<p><strong>(0, 255, 0)</strong> represents pure green.</p>
</li>
<li>
<p><strong>(0, 0, 255)</strong> represents pure blue.</p>
</li>
<li>
<p><strong>(255, 255, 255)</strong> represents white (all channels at maximum intensity).</p>
</li>
<li>
<p><strong>(0, 0, 0)</strong> represents black (all channels at zero intensity).</p>
</li>
</ul>
<p><strong>Example</strong>:<br />
A 2×2 RGB image might look like this:</p>
<table>
<thead>
<tr>
<th><strong>Pixel</strong></th>
<th><strong>RGB Value</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Red</td>
<td>(255, 0, 0)</td>
</tr>
<tr>
<td>Green</td>
<td>(0, 255, 0)</td>
</tr>
<tr>
<td>Blue</td>
<td>(0, 0, 255)</td>
</tr>
<tr>
<td>Yellow</td>
<td>(255, 255, 0)</td>
</tr>
</tbody>
</table>
<p><strong>Matrix Representation</strong>:</p>
<pre><code>Red Channel:   [[255,   0],
                [  0, 255]]

Green Channel: [[  0, 255],
                [  0, 255]]

Blue Channel:  [[  0,   0],
                [255,   0]]
</code></pre>
<hr />
<h4 id="how-images-are-stored-and-processed"><strong>How Images Are Stored and Processed</strong><a class="headerlink" href="#how-images-are-stored-and-processed" title="Permanent link">&para;</a></h4>
<ol>
<li><strong>Grayscale Images</strong>: Stored as a 2D matrix where each value represents the intensity of light at that pixel.</li>
<li><strong>RGB Images</strong>: Stored as a 3D matrix (Height × Width × 3), where the third dimension represents the three color channels (Red, Green, Blue).</li>
</ol>
<hr />
<h4 id="example-in-python"><strong>Example in Python</strong><a class="headerlink" href="#example-in-python" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">import cv2
import numpy as np

# Load a grayscale image
grayscale_image = cv2.imread('example_grayscale.jpg', cv2.IMREAD_GRAYSCALE)
print(&quot;Grayscale Image Shape:&quot;, grayscale_image.shape)
print(&quot;Grayscale Pixel Values:\n&quot;, grayscale_image)

# Load an RGB image
rgb_image = cv2.imread('example_rgb.jpg', cv2.IMREAD_COLOR)
rgb_image = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB
print(&quot;RGB Image Shape:&quot;, rgb_image.shape)
print(&quot;RGB Pixel Values:\n&quot;, rgb_image)
</code></pre>
<hr />
<h4 id="key-takeaways"><strong>Key Takeaways</strong><a class="headerlink" href="#key-takeaways" title="Permanent link">&para;</a></h4>
<ol>
<li>Grayscale images are simpler, with one value per pixel, making them easier to process.</li>
<li>RGB images are more complex, with three values per pixel, allowing for full-color representation.</li>
<li>Both types of images are represented as numerical matrices, which can be processed by machine learning models.</li>
</ol>
<hr />
<h3 id="41-what-are-cnns"><strong>4.1 What are CNN's?</strong><a class="headerlink" href="#41-what-are-cnns" title="Permanent link">&para;</a></h3>
<p>A Convolutional Neural Network (CNN) is a Deep Learning model designed for grid-like data such as images, where a grayscale image is a single H×W (Height x Width) pixel matrix and an RGB image is three H×W (Height x Width) matrices stacked together, and the learnable parameters are the weights and biases.</p>
<ul>
<li>Instead of looking at the whole image at once, CNNs look at <strong>small local regions (patches)</strong> to learn patterns like edges, textures, shapes, and then combine them to recognize higher-level features.</li>
</ul>
<h3 id="42-how-cnns-work"><strong>4.2 How CNNs Work?</strong><a class="headerlink" href="#42-how-cnns-work" title="Permanent link">&para;</a></h3>
<p>A CNN has <strong>three main types of layers</strong>:</p>
<h4 id="421-convolution-layer"><strong>4.2.1 Convolution Layer</strong><a class="headerlink" href="#421-convolution-layer" title="Permanent link">&para;</a></h4>
<p>The convolution layer is the core building block of CNNs. It applies filters (kernels) to the input image to extract features like edges, textures, and patterns. Below, we break down the key concepts of <strong>stride</strong>, <strong>kernel</strong>, and <strong>padding</strong>, using the same matrix for all examples.</p>
<hr />
<h5 id="example-matrix"><strong>Example Matrix</strong><a class="headerlink" href="#example-matrix" title="Permanent link">&para;</a></h5>
<p>We will use the following 5×5 input matrix for all examples:</p>
<pre><code class="language-plaintext">Input Matrix:
[ [ 1   2   3   4   5 ]
  [ 6   7   8   9  10 ]
  [ 11  12  13  14  15 ]
  [ 16  17  18  19  20 ]
  [ 21  22  23  24  25 ] ]
</code></pre>
<hr />
<h5 id="stride"><strong>Stride</strong><a class="headerlink" href="#stride" title="Permanent link">&para;</a></h5>
<ul>
<li><strong>Definition</strong>: Stride determines how the filter (kernel) moves across the input matrix.  </li>
<li><strong>How it works</strong>: A stride of 1 means the filter moves 1 step at a time, while a stride of 2 skips 1 step between positions.  </li>
<li><strong>Effect</strong>: Larger strides reduce the size of the output matrix, while smaller strides preserve more detail.</li>
</ul>
<p><strong>Example</strong>:<br />
Using a 3×3 kernel with a stride of 1:</p>
<pre><code class="language-plaintext">Kernel:
[ [ 1   0   1 ]
  [ 0   1   0 ]
  [ 1   0   1 ] ]
</code></pre>
<p><strong>Step-by-Step Calculation</strong>:<br />
Place the kernel on the top-left corner of the input matrix.
Perform element-wise multiplication and sum the results.
Move the kernel by the stride (1 step in this case) and repeat.</p>
<p><strong>Output Matrix (Stride = 1)</strong>:</p>
<pre><code class="language-plaintext">[ [ 50   60   70 ]
  [ 110  120  130 ]
  [ 170  180  190 ] ]
</code></pre>
<p>With a stride of 2, the kernel skips every other step:</p>
<p><strong>Output Matrix (Stride = 2)</strong>:</p>
<pre><code class="language-plaintext">[ [ 50   70 ]
  [ 170  190 ] ]
</code></pre>
<hr />
<h5 id="kernel-filter"><strong>Kernel (Filter)</strong><a class="headerlink" href="#kernel-filter" title="Permanent link">&para;</a></h5>
<ul>
<li><strong>Definition</strong>: A kernel (or filter) is a small matrix (e.g., 3×3) that slides over the input matrix to detect patterns.  </li>
<li><strong>How it works</strong>: Each kernel performs element-wise multiplication with the input matrix and sums the results to produce a single value in the output matrix.  </li>
<li><strong>Purpose</strong>: Different kernels detect different features, such as edges, corners, or textures.</li>
</ul>
<p><strong>Example</strong>:<br />
Using the same 3×3 kernel as above:</p>
<pre><code class="language-plaintext">Kernel:
[ [ 1   0   1 ]
  [ 0   1   0 ]
  [ 1   0   1 ] ]
</code></pre>
<p><strong>Step-by-Step Calculation</strong>:<br />
Place the kernel on the top-left corner of the input matrix.
Multiply each element of the kernel with the corresponding element of the input matrix.
Sum the results to get the output value for that position.
Slide the kernel to the next position (based on the stride) and repeat.</p>
<p><strong>Output Matrix (Stride = 1)</strong>:</p>
<pre><code class="language-plaintext">[ [ 50   60   70 ]
  [ 110  120  130 ]
  [ 170  180  190 ] ]
</code></pre>
<hr />
<h5 id="padding"><strong>Padding</strong><a class="headerlink" href="#padding" title="Permanent link">&para;</a></h5>
<ul>
<li><strong>Definition</strong>: Padding adds extra pixels (usually zeros) around the edges of the input matrix.  </li>
<li><strong>Why it's needed</strong>: Without padding, the size of the output matrix decreases after each convolution. Padding helps preserve the spatial dimensions of the input.  </li>
<li><strong>Types of Padding</strong>:  </li>
<li><strong>Same Padding</strong>: Adds enough padding to ensure the output size matches the input size.  </li>
<li><strong>Valid Padding</strong>: No padding is added, so the output size is smaller than the input.</li>
</ul>
<p><strong>Example</strong>:<br />
Using the same 5×5 input matrix and 3×3 kernel:</p>
<p><strong>Input Matrix (No Padding)</strong>:</p>
<pre><code class="language-plaintext">[ [ 1   2   3   4   5 ]
  [ 6   7   8   9  10 ]
  [ 11  12  13  14  15 ]
  [ 16  17  18  19  20 ]
  [ 21  22  23  24  25 ] ]
</code></pre>
<p><strong>Input Matrix (With Padding)</strong>:</p>
<pre><code class="language-plaintext">[ [ 0   0   0   0   0   0   0 ]
  [ 0   1   2   3   4   5   0 ]
  [ 0   6   7   8   9  10   0 ]
  [ 0  11  12  13  14  15   0 ]
  [ 0  16  17  18  19  20   0 ]
  [ 0  21  22  23  24  25   0 ]
  [ 0   0   0   0   0   0   0 ] ]
</code></pre>
<p>With padding, the output matrix size remains the same as the input matrix.</p>
<hr />
<h4 id="422-pooling-layer"><strong>4.2.2 Pooling Layer</strong><a class="headerlink" href="#422-pooling-layer" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Definition</strong>: Pooling reduces the size of the feature map by summarizing regions of the input matrix.  </li>
<li><strong>Types</strong>:  </li>
<li><strong>Max Pooling</strong>: Takes the maximum value in each region.  </li>
<li><strong>Average Pooling</strong>: Takes the average value in each region.</li>
</ul>
<p><strong>Example</strong>:<br />
Using the same 5×5 input matrix:</p>
<pre><code class="language-plaintext">Input Matrix:
[ [ 1   2   3   4   5 ]
  [ 6   7   8   9  10 ]
  [ 11  12  13  14  15 ]
  [ 16  17  18  19  20 ]
  [ 21  22  23  24  25 ] ]
</code></pre>
<p><strong>Max Pooling (2×2, Stride = 2)</strong>:</p>
<pre><code class="language-plaintext">[ [ 7   9 ]
  [ 17  19 ] ]
</code></pre>
<p><strong>Average Pooling (2×2, Stride = 2)</strong>:</p>
<pre><code class="language-plaintext">[ [ 6.5   8.5 ]
  [ 16.5  18.5 ] ]
</code></pre>
<p>Pooling reduces the size of the matrix while retaining the most important information.</p>
<hr />
<h4 id="423-flattening-layers"><strong>4.2.3 Flattening Layers</strong><a class="headerlink" href="#423-flattening-layers" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Definition</strong>: Flattening is the process of converting a multi-dimensional feature map (e.g., 2D or 3D) into a 1D vector.</li>
<li><strong>Why it's needed</strong>: Fully connected (dense) layers require a 1D input, so the output of convolution and pooling layers must be flattened before being passed to dense layers.</li>
<li><strong>How it works</strong>: The spatial dimensions (height, width, channels) of the feature map are unrolled into a single vector.</li>
</ul>
<p><strong>Example</strong>:<br />
If the output of the pooling layer is a 3D tensor of shape <code>(4, 4, 8)</code> (Height × Width × Channels), flattening converts it into a 1D vector of size <code>4 × 4 × 8 = 128</code>.</p>
<h4 id="424-fully-connected-layer"><strong>4.2.4 Fully Connected Layer</strong><a class="headerlink" href="#424-fully-connected-layer" title="Permanent link">&para;</a></h4>
<ul>
<li>Predicts the outcome based on the extracted features passed to it.</li>
</ul>
<p><img alt="Example of a CNN" src="../../assets/cnn.png" />
<img alt="Intuition" src="../../assets/Intuition.png" /></p>
<hr />
<h2 id="5-intuition-behind-finding-edges-and-textures-using-cnn-using-mnist-dataset-for-1-layer"><strong>5. Intuition behind finding edges and textures using CNN using MNIST Dataset for 1 layer</strong><a class="headerlink" href="#5-intuition-behind-finding-edges-and-textures-using-cnn-using-mnist-dataset-for-1-layer" title="Permanent link">&para;</a></h2>
<h3 id="51-input-image"><strong>5.1 Input Image</strong><a class="headerlink" href="#51-input-image" title="Permanent link">&para;</a></h3>
<p>The MNIST input is a 28×28 grayscale image containing a handwritten digit.
This raw image serves as the starting point for feature extraction.
Even before convolution, the CNN receives a pixel matrix where:</p>
<p>Dark areas represent the background.</p>
<p>Bright areas represent the handwritten stroke.
<img alt="input image" src="../../assets/input.png" /></p>
<h3 id="52-first-convolution-layer-conv1-detecting-simple-edges"><strong>5.2 First Convolution Layer (Conv1) – Detecting Simple Edges</strong><a class="headerlink" href="#52-first-convolution-layer-conv1-detecting-simple-edges" title="Permanent link">&para;</a></h3>
<p>The first convolution layer applies a set of filters to the input image to detect simple features such as edges and gradients. Each filter produces a <strong>feature map</strong>, which highlights specific patterns in the image. </p>
<ul>
<li>Faint vertical edge getting represented in the first feature map.</li>
</ul>
<p><img alt="input image" src="../../assets/feature_0.png" /></p>
<ul>
<li>Vertical and Horizontal edges together, with the corners, are getting represented in the second feature map, representing 7 as an image.</li>
</ul>
<p><img alt="input image" src="../../assets/feature_1.png" /></p>
<ul>
<li>The background gets represented in the third feature map.</li>
</ul>
<p><img alt="input image" src="../../assets/feature_2.png" /></p>
<ul>
<li>The top vertical edge, and the rightmost horizontal edge gets represented, completing the shape in this particular feature map.</li>
</ul>
<p><img alt="input image" src="../../assets/feature_3.png" /></p>
<ul>
<li>The rightmost curve, gets represented in this particular feature map.</li>
</ul>
<p><img alt="input image" src="../../assets/feature_4.png" /></p>
<ul>
<li>In this feature map, the topmost horizontal curve, and the leftmost vertical curve faintly gets represented.</li>
</ul>
<p><img alt="input image" src="../../assets/feature_5.png" /></p>
<p>Each feature map is the result of applying a specific filter (kernel) to the input image, followed by the ReLU activation function, which ensures that only positive values are retained. These feature maps are then passed to the next layer for further processing.</p>
<hr />
<h2 id="6-tensors-parallelism-and-training-in-cnns"><strong>6. Tensors, Parallelism, and Training in CNNs</strong><a class="headerlink" href="#6-tensors-parallelism-and-training-in-cnns" title="Permanent link">&para;</a></h2>
<p>In this section, we will explore the fundamental building blocks of deep learning — tensors, the importance of GPUs/TPUs for parallelism, and how the training process works in CNNs.</p>
<hr />
<h3 id="61-what-are-tensors"><strong>6.1 What Are Tensors?</strong><a class="headerlink" href="#61-what-are-tensors" title="Permanent link">&para;</a></h3>
<p>Tensors are the core data structure used in deep learning. They are generalizations of matrices to higher dimensions and are used to represent data in a structured way.</p>
<ul>
<li><strong>Scalars (0D)</strong>: A single number (e.g., <code>5</code>).</li>
<li><strong>Vectors (1D)</strong>: A list of numbers (e.g., <code>[1, 2, 3]</code>).</li>
<li><strong>Matrices (2D)</strong>: A grid of numbers (e.g., a 2×2 matrix):
  <code>plaintext
  [ [1, 2],
    [3, 4] ]</code></li>
<li><strong>Tensors (nD)</strong>: Generalized n-dimensional arrays. For example:</li>
<li>A 3D tensor could represent an RGB image (Height × Width × Channels):
    <code>plaintext
    [ [ [R1, G1, B1], [R2, G2, B2] ],
      [ [R3, G3, B3], [R4, G4, B4] ] ]</code></li>
<li>A 4D tensor could represent a batch of images (Batch × Height × Width × Channels).</li>
</ul>
<p><strong>Why Tensors?</strong>
- Tensors allow us to represent complex data like images, videos, and text in a structured way.
- They are optimized for mathematical operations like matrix multiplication, which is the backbone of deep learning.</p>
<hr />
<h3 id="62-why-gpus-and-tpus-are-essential"><strong>6.2 Why GPUs and TPUs Are Essential</strong><a class="headerlink" href="#62-why-gpus-and-tpus-are-essential" title="Permanent link">&para;</a></h3>
<p>Images are essentially large matrices, and processing them requires a lot of computational power. GPUs (Graphics Processing Units) and TPUs (Tensor Processing Units) are specialized hardware designed to handle these computations efficiently.</p>
<h4 id="621-the-role-of-gpus"><strong>6.2.1 The Role of GPUs</strong><a class="headerlink" href="#621-the-role-of-gpus" title="Permanent link">&para;</a></h4>
<ul>
<li>GPUs are designed for parallel processing, making them ideal for matrix operations.</li>
<li>In CNNs, operations like convolution and backpropagation involve millions of matrix multiplications, which GPUs can handle simultaneously.</li>
<li>Example: A single image of size 224×224×3 (Height × Width × Channels) has over 150,000 pixels. Processing a batch of 32 images involves over 4.8 million pixels, which GPUs can process in parallel.</li>
</ul>
<h4 id="622-the-role-of-tpus"><strong>6.2.2 The Role of TPUs</strong><a class="headerlink" href="#622-the-role-of-tpus" title="Permanent link">&para;</a></h4>
<ul>
<li>TPUs are specialized hardware designed by Google for deep learning tasks.</li>
<li>They are optimized for tensor operations and are faster than GPUs for certain workloads.</li>
<li>TPUs are commonly used for large-scale training tasks, such as training models on massive datasets like ImageNet.</li>
</ul>
<h4 id="623-why-parallelism-matters"><strong>6.2.3 Why Parallelism Matters</strong><a class="headerlink" href="#623-why-parallelism-matters" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Matrix Operations</strong>: Convolutions, pooling, and fully connected layers involve matrix multiplications, which are computationally expensive.</li>
<li><strong>Batch Processing</strong>: Training on batches of data requires simultaneous processing of multiple images, which GPUs/TPUs excel at.</li>
<li><strong>Speed</strong>: Without GPUs/TPUs, training deep learning models would take days or weeks instead of hours.</li>
</ul>
<hr />
<h3 id="63-the-training-cycle-in-cnns"><strong>6.3 The Training Cycle in CNNs</strong><a class="headerlink" href="#63-the-training-cycle-in-cnns" title="Permanent link">&para;</a></h3>
<p>Training a CNN involves multiple steps, which are repeated for several epochs until the model converges. Here's how the training process works:</p>
<h4 id="631-forward-propagation"><strong>6.3.1 Forward Propagation</strong><a class="headerlink" href="#631-forward-propagation" title="Permanent link">&para;</a></h4>
<ul>
<li>The input image is passed through the network layer by layer.</li>
<li>Each layer performs operations like convolution, activation, and pooling to extract features.</li>
<li>The final layer produces predictions (e.g., class probabilities for classification tasks).</li>
</ul>
<h4 id="632-loss-calculation"><strong>6.3.2 Loss Calculation</strong><a class="headerlink" href="#632-loss-calculation" title="Permanent link">&para;</a></h4>
<ul>
<li>The model's predictions are compared to the true labels using a loss function (e.g., cross-entropy loss for classification).</li>
<li>The loss quantifies how far the predictions are from the actual labels.</li>
</ul>
<h4 id="633-backpropagation"><strong>6.3.3 Backpropagation</strong><a class="headerlink" href="#633-backpropagation" title="Permanent link">&para;</a></h4>
<ul>
<li>Backpropagation computes the gradients of the loss with respect to the model's parameters (weights and biases).</li>
<li>Gradients are calculated using the chain rule of calculus, starting from the output layer and propagating backward through the network.</li>
</ul>
<h4 id="634-weight-updates"><strong>6.3.4 Weight Updates</strong><a class="headerlink" href="#634-weight-updates" title="Permanent link">&para;</a></h4>
<ul>
<li>The gradients are used to update the model's parameters using an optimizer (e.g., SGD, Adam).</li>
<li>The learning rate controls the size of the updates.</li>
</ul>
<h4 id="635-epochs-and-iterations"><strong>6.3.5 Epochs and Iterations</strong><a class="headerlink" href="#635-epochs-and-iterations" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Epoch</strong>: One complete pass through the entire training dataset.</li>
<li><strong>Iteration</strong>: One update of the model's parameters, typically after processing a single batch of data.</li>
<li>Training involves multiple epochs, with the model improving its predictions over time.</li>
</ul>
<hr />
<h3 id="64-how-cnn-training-differs-from-rnn-training"><strong>6.4 How CNN Training Differs from RNN Training</strong><a class="headerlink" href="#64-how-cnn-training-differs-from-rnn-training" title="Permanent link">&para;</a></h3>
<p>While the core concepts of training (forward propagation, backpropagation, and weight updates) are the same for CNNs and RNNs, there are key differences in how they process data:</p>
<h4 id="641-data-structure"><strong>6.4.1 Data Structure</strong><a class="headerlink" href="#641-data-structure" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>CNNs</strong>: Process grid-like data (e.g., images) where spatial relationships are important.</li>
<li><strong>RNNs</strong>: Process sequential data (e.g., text, time series) where temporal relationships are important.</li>
</ul>
<h4 id="642-backpropagation"><strong>6.4.2 Backpropagation</strong><a class="headerlink" href="#642-backpropagation" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>CNNs</strong>: Use standard backpropagation to compute gradients.</li>
<li><strong>RNNs</strong>: Use backpropagation through time (BPTT) to handle sequential dependencies.</li>
</ul>
<h4 id="643-epochs"><strong>6.4.3 Epochs</strong><a class="headerlink" href="#643-epochs" title="Permanent link">&para;</a></h4>
<ul>
<li>In CNNs, each epoch processes the entire dataset of images.</li>
<li>In RNNs, each epoch processes sequences, which may involve additional steps to handle variable sequence lengths.</li>
</ul>
<h4 id="644-parallelism"><strong>6.4.4 Parallelism</strong><a class="headerlink" href="#644-parallelism" title="Permanent link">&para;</a></h4>
<ul>
<li>CNNs benefit more from GPU/TPU parallelism because images can be processed independently in batches.</li>
<li>RNNs are less parallelizable due to their sequential nature, where each step depends on the previous one.</li>
</ul>
<hr />
<h3 id="65-summary"><strong>6.5 Summary</strong><a class="headerlink" href="#65-summary" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Tensors</strong>: The fundamental data structure in deep learning, representing data as n-dimensional arrays.</li>
<li><strong>GPUs/TPUs</strong>: Essential for efficient training of CNNs due to their ability to handle parallel computations.</li>
<li><strong>Training Cycle</strong>: Involves forward propagation, loss calculation, backpropagation, and weight updates, repeated over multiple epochs.</li>
<li><strong>CNN vs. RNN Training</strong>: While the core concepts are similar, CNNs process grid-like data in parallel, whereas RNNs process sequential data step by step.</li>
</ul>
<p>Understanding these concepts is crucial for building and optimizing deep learning models, especially when working with large datasets and complex architectures.</p>
<hr />
<h2 id="7-advantages-and-disadvantages-of-cnn"><strong>7. Advantages and Disadvantages of CNN</strong><a class="headerlink" href="#7-advantages-and-disadvantages-of-cnn" title="Permanent link">&para;</a></h2>
<h3 id="71-advantages"><strong>7.1 Advantages</strong><a class="headerlink" href="#71-advantages" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Learns hierarchical spatial features</strong> (edges → textures → objects).  </li>
<li><strong>Parameter sharing &amp; local connectivity</strong> → fewer parameters and efficient learning for images.  </li>
<li><strong>State-of-the-art</strong> for vision tasks and has efficient variants for edge/mobile.  </li>
<li><strong>Robust to translation, scaling, and rotation</strong> due to convolution and pooling layers.  </li>
<li><strong>Feature extraction is automatic</strong> — no need for manual feature engineering.  </li>
<li><strong>Versatility</strong> — can be applied to images, videos, and even sequential data like audio or text (with modifications).  </li>
</ul>
<h4 id="711-cnns-for-videos"><strong>7.1.1 CNNs for Videos</strong><a class="headerlink" href="#711-cnns-for-videos" title="Permanent link">&para;</a></h4>
<ul>
<li>Videos are sequences of frames, where each frame is treated as an image. CNNs extract spatial features from each frame.</li>
<li>Temporal relationships across frames can be modeled using architectures like RNNs, LSTMs, or 3D CNNs.</li>
<li><strong>Applications</strong>: Action recognition, video classification, and object tracking.</li>
</ul>
<h3 id="72-disadvantages"><strong>7.2 Disadvantages</strong><a class="headerlink" href="#72-disadvantages" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Data hungry</strong> — needs large labeled datasets for best performance.  </li>
<li><strong>Compute and memory intensive</strong> (training often requires GPUs/TPUs).  </li>
<li><strong>Can overfit</strong> on small datasets.  </li>
<li><strong>Lack of interpretability</strong> — CNNs are often considered "black boxes" due to their complexity.  </li>
<li><strong>Requires significant hyperparameter tuning</strong> (e.g., kernel size, stride, number of filters) for optimal performance.  </li>
</ul>
<hr />
<p>CNN_Model_Training colab link: <a href="https://colab.research.google.com/drive/11mLrtD7BT0J9wWm1ugqtHlw1g81FfiAl?usp=sharing">CNN_Model_Training</a></p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024 - ACM BITS Pilani Dubai Campus
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://instagram.com/acmbpdc" target="_blank" rel="noopener" title="instagram.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M224.3 141a115 115 0 1 0-.6 230 115 115 0 1 0 .6-230m-.6 40.4a74.6 74.6 0 1 1 .6 149.2 74.6 74.6 0 1 1-.6-149.2m93.4-45.1a26.8 26.8 0 1 1 53.6 0 26.8 26.8 0 1 1-53.6 0m129.7 27.2c-1.7-35.9-9.9-67.7-36.2-93.9-26.2-26.2-58-34.4-93.9-36.2-37-2.1-147.9-2.1-184.9 0-35.8 1.7-67.6 9.9-93.9 36.1s-34.4 58-36.2 93.9c-2.1 37-2.1 147.9 0 184.9 1.7 35.9 9.9 67.7 36.2 93.9s58 34.4 93.9 36.2c37 2.1 147.9 2.1 184.9 0 35.9-1.7 67.7-9.9 93.9-36.2 26.2-26.2 34.4-58 36.2-93.9 2.1-37 2.1-147.8 0-184.8M399 388c-7.8 19.6-22.9 34.7-42.6 42.6-29.5 11.7-99.5 9-132.1 9s-102.7 2.6-132.1-9c-19.6-7.8-34.7-22.9-42.6-42.6-11.7-29.5-9-99.5-9-132.1s-2.6-102.7 9-132.1c7.8-19.6 22.9-34.7 42.6-42.6 29.5-11.7 99.5-9 132.1-9s102.7-2.6 132.1 9c19.6 7.8 34.7 22.9 42.6 42.6 11.7 29.5 9 99.5 9 132.1s2.7 102.7-9 132.1"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/acmbpdc" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://discord.gg/DYQdxquYwP" target="_blank" rel="noopener" title="discord.gg" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M492.5 69.8c-.2-.3-.4-.6-.8-.7-38.1-17.5-78.4-30-119.7-37.1-.4-.1-.8 0-1.1.1s-.6.4-.8.8c-5.5 9.9-10.5 20.2-14.9 30.6-44.6-6.8-89.9-6.8-134.4 0-4.5-10.5-9.5-20.7-15.1-30.6-.2-.3-.5-.6-.8-.8s-.7-.2-1.1-.2C162.5 39 122.2 51.5 84.1 69c-.3.1-.6.4-.8.7C7.1 183.5-13.8 294.6-3.6 404.2c0 .3.1.5.2.8s.3.4.5.6c44.4 32.9 94 58 146.8 74.2.4.1.8.1 1.1 0s.7-.4.9-.7c11.3-15.4 21.4-31.8 30-48.8.1-.2.2-.5.2-.8s0-.5-.1-.8-.2-.5-.4-.6-.4-.3-.7-.4c-15.8-6.1-31.2-13.4-45.9-21.9-.3-.2-.5-.4-.7-.6s-.3-.6-.3-.9 0-.6.2-.9.3-.5.6-.7c3.1-2.3 6.2-4.7 9.1-7.1.3-.2.6-.4.9-.4s.7 0 1 .1c96.2 43.9 200.4 43.9 295.5 0 .3-.1.7-.2 1-.2s.7.2.9.4c2.9 2.4 6 4.9 9.1 7.2.2.2.4.4.6.7s.2.6.2.9-.1.6-.3.9-.4.5-.6.6c-14.7 8.6-30 15.9-45.9 21.8-.2.1-.5.2-.7.4s-.3.4-.4.7-.1.5-.1.8.1.5.2.8c8.8 17 18.8 33.3 30 48.8.2.3.6.6.9.7s.8.1 1.1 0c52.9-16.2 102.6-41.3 147.1-74.2.2-.2.4-.4.5-.6s.2-.5.2-.8c12.3-126.8-20.5-236.9-86.9-334.5zm-302 267.7c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.4 59.2-52.8 59.2m195.4 0c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.2 59.2-52.8 59.2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "header.autohide"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>