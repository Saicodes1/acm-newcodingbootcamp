
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A template site, replace this with the actual description">
      
      
        <meta name="author" content="ACM BPDC">
      
      
        <link rel="canonical" href="https://riyanbhargava.github.io/acm-ml-workshop/day2/day2/">
      
      
        <link rel="prev" href="../../day1/day1/">
      
      
        <link rel="next" href="../../day3/day3/">
      
      
      <link rel="icon" href="../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.23">
    
    
      
        <title>Model Training and Analysis - ML Workshop</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#day-2-model-training-and-analysis" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="ML Workshop" class="md-header__button md-logo" aria-label="ML Workshop" data-md-component="logo">
      
  <img src="../../assets/ACM_Logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ML Workshop
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Model Training and Analysis
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/RiyanBhargava/acm-ml-workshop" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    RiyanBhargava/acm-ml-workshop
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../day1/day1/" class="md-tabs__link">
        
  
  
    
  
  Data Cleaning and Feature Engineering

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
  
    
  
  Model Training and Analysis

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../day3/day3/" class="md-tabs__link">
        
  
  
    
  
  Deep Learning & NLP

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../day4/day4/" class="md-tabs__link">
        
  
  
    
  
  DL with CNN and Image Detection

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="ML Workshop" class="md-nav__button md-logo" aria-label="ML Workshop" data-md-component="logo">
      
  <img src="../../assets/ACM_Logo.png" alt="logo">

    </a>
    ML Workshop
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/RiyanBhargava/acm-ml-workshop" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    RiyanBhargava/acm-ml-workshop
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../day1/day1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Data Cleaning and Feature Engineering
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Model Training and Analysis
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Model Training and Analysis
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#complete-documentation-guide" class="md-nav__link">
    <span class="md-ellipsis">
      Complete Documentation Guide
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-overview" class="md-nav__link">
    <span class="md-ellipsis">
      1. Overview
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Overview">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#workshop-resources-make-a-copy-and-run-the-cells" class="md-nav__link">
    <span class="md-ellipsis">
      Workshop Resources (Make a copy and run the cells) :
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-dataset-information" class="md-nav__link">
    <span class="md-ellipsis">
      2. Dataset Information
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Dataset Information">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#preprocessed-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Preprocessed Dataset
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature-preparation" class="md-nav__link">
    <span class="md-ellipsis">
      Feature Preparation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-overfitting-and-underfitting" class="md-nav__link">
    <span class="md-ellipsis">
      3. Overfitting and Underfitting
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Overfitting and Underfitting">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-overfitting" class="md-nav__link">
    <span class="md-ellipsis">
      3.1. Overfitting
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-underfitting" class="md-nav__link">
    <span class="md-ellipsis">
      3.2. Underfitting
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-train-test-split" class="md-nav__link">
    <span class="md-ellipsis">
      4. Train-Test Split
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Train-Test Split">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-is-train-test-split" class="md-nav__link">
    <span class="md-ellipsis">
      What is Train-Test Split?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#41-why-split-data" class="md-nav__link">
    <span class="md-ellipsis">
      4.1. Why Split Data?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-types-of-machine-learning-problems" class="md-nav__link">
    <span class="md-ellipsis">
      5. Types of Machine Learning Problems
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Types of Machine Learning Problems">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-regression-problem" class="md-nav__link">
    <span class="md-ellipsis">
      5.1. Regression Problem
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-classification-problem" class="md-nav__link">
    <span class="md-ellipsis">
      5.2. Classification Problem
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-regression-models" class="md-nav__link">
    <span class="md-ellipsis">
      6. Regression Models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Regression Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-linear-regression" class="md-nav__link">
    <span class="md-ellipsis">
      6.1. Linear Regression
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62-decision-tree-regressor" class="md-nav__link">
    <span class="md-ellipsis">
      6.2. Decision Tree Regressor
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63-random-forest-regressor" class="md-nav__link">
    <span class="md-ellipsis">
      6.3. Random Forest Regressor
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#64-k-nearest-neighbors-knn-regressor" class="md-nav__link">
    <span class="md-ellipsis">
      6.4. K-Nearest Neighbors (KNN) Regressor
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-classification-models" class="md-nav__link">
    <span class="md-ellipsis">
      7. Classification Models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Classification Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71-logistic-regression" class="md-nav__link">
    <span class="md-ellipsis">
      7.1. Logistic Regression
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-decision-tree-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      7.2. Decision Tree Classifier
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73-random-forest-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      7.3. Random Forest Classifier
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74-k-nearest-neighbors-knn-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      7.4. K-Nearest Neighbors (KNN) Classifier
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-evaluation-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      8. Evaluation Metrics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. Evaluation Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#section-81-regression-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      Section 8.1 : Regression Metrics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Section 8.1 : Regression Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#811-mean-squared-error-mse" class="md-nav__link">
    <span class="md-ellipsis">
      8.1.1. Mean Squared Error (MSE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#812-root-mean-squared-error-rmse" class="md-nav__link">
    <span class="md-ellipsis">
      8.1.2. Root Mean Squared Error (RMSE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#813-mean-absolute-error-mae" class="md-nav__link">
    <span class="md-ellipsis">
      8.1.3. Mean Absolute Error (MAE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#814-r2-score-r-squared" class="md-nav__link">
    <span class="md-ellipsis">
      8.1.4. R¬≤ Score (R-Squared)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#82-classification-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      8.2. Classification Metrics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8.2. Classification Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#821-accuracy" class="md-nav__link">
    <span class="md-ellipsis">
      8.2.1. Accuracy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#822-confusion-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      8.2.2. Confusion Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#823-precision" class="md-nav__link">
    <span class="md-ellipsis">
      8.2.3. Precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#824-recall-sensitivity" class="md-nav__link">
    <span class="md-ellipsis">
      8.2.4. Recall (Sensitivity)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#825-f1-score" class="md-nav__link">
    <span class="md-ellipsis">
      8.2.5. F1-Score
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-model-comparison-regression-results" class="md-nav__link">
    <span class="md-ellipsis">
      9. Model Comparison (Regression Results)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Model Comparison (Regression Results)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-regression-performance-ranking" class="md-nav__link">
    <span class="md-ellipsis">
      9.1. Regression Performance Ranking
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-key-observations" class="md-nav__link">
    <span class="md-ellipsis">
      9.2. Key Observations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-model-comparison-classification-results" class="md-nav__link">
    <span class="md-ellipsis">
      10. Model Comparison (Classification Results)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="10. Model Comparison (Classification Results)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#101-classification-performance-ranking" class="md-nav__link">
    <span class="md-ellipsis">
      10.1. Classification Performance Ranking
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#102-confusion-matrix-for-all-models" class="md-nav__link">
    <span class="md-ellipsis">
      10.2. Confusion Matrix for all models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#103-key-observations" class="md-nav__link">
    <span class="md-ellipsis">
      10.3. Key Observations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-general-ml-best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      11. General ML Best Practices
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-summary" class="md-nav__link">
    <span class="md-ellipsis">
      12. Summary
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../day3/day3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Deep Learning & NLP
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../day4/day4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DL with CNN and Image Detection
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#complete-documentation-guide" class="md-nav__link">
    <span class="md-ellipsis">
      Complete Documentation Guide
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-overview" class="md-nav__link">
    <span class="md-ellipsis">
      1. Overview
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Overview">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#workshop-resources-make-a-copy-and-run-the-cells" class="md-nav__link">
    <span class="md-ellipsis">
      Workshop Resources (Make a copy and run the cells) :
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-dataset-information" class="md-nav__link">
    <span class="md-ellipsis">
      2. Dataset Information
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Dataset Information">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#preprocessed-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Preprocessed Dataset
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature-preparation" class="md-nav__link">
    <span class="md-ellipsis">
      Feature Preparation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-overfitting-and-underfitting" class="md-nav__link">
    <span class="md-ellipsis">
      3. Overfitting and Underfitting
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Overfitting and Underfitting">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-overfitting" class="md-nav__link">
    <span class="md-ellipsis">
      3.1. Overfitting
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-underfitting" class="md-nav__link">
    <span class="md-ellipsis">
      3.2. Underfitting
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-train-test-split" class="md-nav__link">
    <span class="md-ellipsis">
      4. Train-Test Split
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Train-Test Split">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-is-train-test-split" class="md-nav__link">
    <span class="md-ellipsis">
      What is Train-Test Split?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#41-why-split-data" class="md-nav__link">
    <span class="md-ellipsis">
      4.1. Why Split Data?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-types-of-machine-learning-problems" class="md-nav__link">
    <span class="md-ellipsis">
      5. Types of Machine Learning Problems
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Types of Machine Learning Problems">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-regression-problem" class="md-nav__link">
    <span class="md-ellipsis">
      5.1. Regression Problem
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-classification-problem" class="md-nav__link">
    <span class="md-ellipsis">
      5.2. Classification Problem
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-regression-models" class="md-nav__link">
    <span class="md-ellipsis">
      6. Regression Models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Regression Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-linear-regression" class="md-nav__link">
    <span class="md-ellipsis">
      6.1. Linear Regression
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62-decision-tree-regressor" class="md-nav__link">
    <span class="md-ellipsis">
      6.2. Decision Tree Regressor
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63-random-forest-regressor" class="md-nav__link">
    <span class="md-ellipsis">
      6.3. Random Forest Regressor
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#64-k-nearest-neighbors-knn-regressor" class="md-nav__link">
    <span class="md-ellipsis">
      6.4. K-Nearest Neighbors (KNN) Regressor
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-classification-models" class="md-nav__link">
    <span class="md-ellipsis">
      7. Classification Models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Classification Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71-logistic-regression" class="md-nav__link">
    <span class="md-ellipsis">
      7.1. Logistic Regression
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-decision-tree-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      7.2. Decision Tree Classifier
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73-random-forest-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      7.3. Random Forest Classifier
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74-k-nearest-neighbors-knn-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      7.4. K-Nearest Neighbors (KNN) Classifier
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-evaluation-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      8. Evaluation Metrics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. Evaluation Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#section-81-regression-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      Section 8.1 : Regression Metrics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Section 8.1 : Regression Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#811-mean-squared-error-mse" class="md-nav__link">
    <span class="md-ellipsis">
      8.1.1. Mean Squared Error (MSE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#812-root-mean-squared-error-rmse" class="md-nav__link">
    <span class="md-ellipsis">
      8.1.2. Root Mean Squared Error (RMSE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#813-mean-absolute-error-mae" class="md-nav__link">
    <span class="md-ellipsis">
      8.1.3. Mean Absolute Error (MAE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#814-r2-score-r-squared" class="md-nav__link">
    <span class="md-ellipsis">
      8.1.4. R¬≤ Score (R-Squared)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#82-classification-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      8.2. Classification Metrics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8.2. Classification Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#821-accuracy" class="md-nav__link">
    <span class="md-ellipsis">
      8.2.1. Accuracy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#822-confusion-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      8.2.2. Confusion Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#823-precision" class="md-nav__link">
    <span class="md-ellipsis">
      8.2.3. Precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#824-recall-sensitivity" class="md-nav__link">
    <span class="md-ellipsis">
      8.2.4. Recall (Sensitivity)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#825-f1-score" class="md-nav__link">
    <span class="md-ellipsis">
      8.2.5. F1-Score
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-model-comparison-regression-results" class="md-nav__link">
    <span class="md-ellipsis">
      9. Model Comparison (Regression Results)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Model Comparison (Regression Results)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-regression-performance-ranking" class="md-nav__link">
    <span class="md-ellipsis">
      9.1. Regression Performance Ranking
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-key-observations" class="md-nav__link">
    <span class="md-ellipsis">
      9.2. Key Observations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-model-comparison-classification-results" class="md-nav__link">
    <span class="md-ellipsis">
      10. Model Comparison (Classification Results)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="10. Model Comparison (Classification Results)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#101-classification-performance-ranking" class="md-nav__link">
    <span class="md-ellipsis">
      10.1. Classification Performance Ranking
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#102-confusion-matrix-for-all-models" class="md-nav__link">
    <span class="md-ellipsis">
      10.2. Confusion Matrix for all models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#103-key-observations" class="md-nav__link">
    <span class="md-ellipsis">
      10.3. Key Observations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-general-ml-best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      11. General ML Best Practices
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-summary" class="md-nav__link">
    <span class="md-ellipsis">
      12. Summary
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="day-2-model-training-and-analysis">Day 2: Model Training and Analysis<a class="headerlink" href="#day-2-model-training-and-analysis" title="Permanent link">&para;</a></h1>
<h2 id="complete-documentation-guide">Complete Documentation Guide<a class="headerlink" href="#complete-documentation-guide" title="Permanent link">&para;</a></h2>
<hr />
<h2 id="1-overview">1. Overview<a class="headerlink" href="#1-overview" title="Permanent link">&para;</a></h2>
<p>This workshop introduces fundamental machine learning concepts with practical implementation. You'll learn how to:
- Split data for training and testing
- Implement multiple regression and classification models
- Evaluate model performance
- Compare and select the best model</p>
<p><strong>Dataset</strong>: Real estate pricing data </p>
<h3 id="workshop-resources-make-a-copy-and-run-the-cells">Workshop Resources (Make a copy and run the cells) :<a class="headerlink" href="#workshop-resources-make-a-copy-and-run-the-cells" title="Permanent link">&para;</a></h3>
<ol>
<li>
<p><strong>Model Training(Regression) :</strong>  <br />
<a href="https://colab.research.google.com/drive/1OJKjqnp6zMdjilnRdZkCm-De1M91Ax8v?usp=sharing">ML_Workshop_Day2_Regression</a></p>
</li>
<li>
<p><strong>Preprocessing of Classification dataset :</strong><br />
<a href="https://colab.research.google.com/drive/1DvOHTXz8iPYrH-0NSuyq19W1_E-TBpey?usp=sharing">Drugclassification_Preprocessing</a></p>
</li>
<li>
<p><strong>Model Training(Classification) :</strong><br />
<a href="https://colab.research.google.com/drive/1eVj2YmoO9bbze7IZnl1IsBGroT4skyxm?usp=sharing">ML_Worshop_Day2_Classification</a></p>
</li>
<li>
<p><strong>Dataset Files :</strong><br />
<a href="../../files/day2/Datasets.zip">Datasets</a></p>
</li>
</ol>
<hr />
<h2 id="2-dataset-information">2. Dataset Information<a class="headerlink" href="#2-dataset-information" title="Permanent link">&para;</a></h2>
<h3 id="preprocessed-dataset">Preprocessed Dataset<a class="headerlink" href="#preprocessed-dataset" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Total Records</strong>: 10,835 properties</li>
<li><strong>Features</strong>: 246 (after preprocessing)</li>
<li><strong>Target Variable</strong>: <code>price</code> (continuous numerical value) - that we want to predict</li>
</ul>
<h3 id="feature-preparation">Feature Preparation<a class="headerlink" href="#feature-preparation" title="Permanent link">&para;</a></h3>
<ul>
<li>The first step we do after pre processing our dataset, is split the features and target</li>
<li>Target : what we are predicting</li>
<li>Features : the properties that we use to predict certain value</li>
</ul>
<pre><code class="language-python"># Separating features and target
# Features: drop 'price' (target), keep all others
feature_cols = [col for col in df1.columns if col != 'price']
X = df1[feature_cols]
y = df1['price']


# Dataset shape
Features: (10835, 244)
Target: (10835,)
</code></pre>
<hr />
<h2 id="3-overfitting-and-underfitting">3. Overfitting and Underfitting<a class="headerlink" href="#3-overfitting-and-underfitting" title="Permanent link">&para;</a></h2>
<p>When building machine learning models, the goal is to <strong>capture the true underlying patterns in data</strong> so the model can <strong>generalize</strong> to new, unseen examples.  </p>
<p>However, models can sometimes go wrong in two common ways:</p>
<ol>
<li><strong>Overfitting</strong></li>
<li><strong>Underfitting</strong> </li>
</ol>
<p><img alt="Underfit,Goodfit and Overfit curves" src="../../assets/image13.png" /></p>
<p>Striking the <strong>right balance</strong> between underfitting and overfitting is key to building robust machine learning models.</p>
<h3 id="31-overfitting">3.1. Overfitting<a class="headerlink" href="#31-overfitting" title="Permanent link">&para;</a></h3>
<p>Overfitting happens when a model learns too much from the training data, including details that don‚Äôt matter (like noise or outliers).</p>
<p><strong>Example :</strong>
- Imagine fitting a very complicated curve to a set of points. The curve will go through every point, but it won‚Äôt represent the actual pattern.
- As a result, the model works great on training data but fails when tested on new data.</p>
<p><img alt="An example of overfit curve" src="../../assets/image14.png" /></p>
<p><strong>Reasons for Overfitting:</strong></p>
<ol>
<li>High variance and low bias.</li>
<li>The model is too complex.</li>
<li>The size of the training data.</li>
</ol>
<h3 id="32-underfitting">3.2. Underfitting<a class="headerlink" href="#32-underfitting" title="Permanent link">&para;</a></h3>
<p>Underfitting is the opposite of overfitting. It happens when a model is too simple to capture what‚Äôs going on in the data.</p>
<p><strong>Example:</strong>
- Imagine drawing a straight line to fit points that actually follow a curve. The line misses most of the pattern.
- In this case, the model doesn‚Äôt work well on either the training or testing data.</p>
<p><img alt="An example of underfit curve" src="../../assets/image15.png" /></p>
<p><strong>Reasons for Underfitting:</strong></p>
<ol>
<li>The model is too simple, So it may be not capable to represent the complexities in the data.</li>
<li>The input features which is used to train the model is not the adequate representations of underlying factors influencing the target variable.</li>
<li>The size of the training dataset used is not enough.</li>
<li>Features are not scaled.</li>
</ol>
<h2 id="4-train-test-split">4. Train-Test Split<a class="headerlink" href="#4-train-test-split" title="Permanent link">&para;</a></h2>
<h3 id="what-is-train-test-split">What is Train-Test Split?<a class="headerlink" href="#what-is-train-test-split" title="Permanent link">&para;</a></h3>
<p>Train-test split divides your dataset into two parts:</p>
<p><img alt="Visual Representation of Train-Test Split" src="../../assets/image1.png" /></p>
<p><strong>Training Set (80%)</strong>: Used to teach the model
- Model learns patterns from this data
- Used for fitting/training algorithms</p>
<p><strong>Testing Set (20%)</strong>: Used to evaluate the model
- Model has never seen this data
- Tests how well model generalizes to new data</p>
<h3 id="implementation">Implementation<a class="headerlink" href="#implementation" title="Permanent link">&para;</a></h3>
<pre><code class="language-python">X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state=42)

#test_size -&gt; indicates that 20% is for testing and 80% is for training

#random_state -&gt; reproducibility - ensures same kind of split occurs everytime
</code></pre>
<h3 id="41-why-split-data">4.1. Why Split Data?<a class="headerlink" href="#41-why-split-data" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Prevents Overfitting</strong>: Model doesn't memorize training data</li>
<li><strong>Tests Generalization</strong>: Evaluates performance on unseen data</li>
<li><strong>Realistic Performance</strong>: Simulates real-world predictions</li>
</ul>
<hr />
<h2 id="5-types-of-machine-learning-problems">5. Types of Machine Learning Problems<a class="headerlink" href="#5-types-of-machine-learning-problems" title="Permanent link">&para;</a></h2>
<p>In supervised learning, problems are usually divided into two types :   </p>
<ul>
<li><strong>Regression Problem</strong></li>
<li><strong>Classification Problem</strong></li>
</ul>
<h3 id="51-regression-problem">5.1. Regression Problem<a class="headerlink" href="#51-regression-problem" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Goal :</strong> To predict a continuous numeric value.</li>
<li>
<p>Regression models try to find relationships between input variables (features) and a continuous output.</p>
</li>
<li>
<p>Examples:</p>
<ul>
<li>Predicting house prices üè†</li>
<li>Estimating temperature üå°Ô∏è</li>
<li>Forecasting stock prices üìà  </li>
</ul>
</li>
<li>
<p>Common Algorithms:</p>
<ol>
<li>Linear Regression    </li>
<li>Decision Tree Regressor</li>
<li>Random Forest Regressor</li>
<li>K - Nearest Neighbors Regressor</li>
</ol>
</li>
<li>
<p>Evaluation Metrics:</p>
<ol>
<li>Mean Squared Error (MSE)</li>
<li>Root Mean Squared Error (RMSE)</li>
<li>Mean Absolute Error (MAE)</li>
<li>R¬≤ Score</li>
</ol>
</li>
</ul>
<h3 id="52-classification-problem">5.2. Classification Problem<a class="headerlink" href="#52-classification-problem" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Goal :</strong> To predict a discrete label or category.</li>
<li>
<p>Classification models learn to separate data into different classes.</p>
</li>
<li>
<p>Examples:</p>
<ul>
<li>Email spam detection ‚úâÔ∏è</li>
<li>Disease diagnosis (positive/negative) üß¨</li>
<li>Image recognition (cat vs. dog) üê±üê∂ </li>
</ul>
</li>
<li>
<p>Common Algorithms:</p>
<ol>
<li>Logistic Regression</li>
<li>Decision Tree Classifier</li>
<li>Random Forest Classifier</li>
<li>k-Nearest Neighbors (KNN)</li>
</ol>
</li>
<li>
<p>Evaluation Metrics:</p>
<ol>
<li>Accuracy</li>
<li>Precision &amp; Recall</li>
<li>F1 Score</li>
<li>Confusion Matrix</li>
</ol>
</li>
</ul>
<hr />
<h2 id="6-regression-models">6. Regression Models<a class="headerlink" href="#6-regression-models" title="Permanent link">&para;</a></h2>
<p>Regression predicts <strong>continuous numerical values</strong> (e.g., house prices, temperature, sales).</p>
<hr />
<h3 id="61-linear-regression">6.1. Linear Regression<a class="headerlink" href="#61-linear-regression" title="Permanent link">&para;</a></h3>
<p><strong>How it works</strong>: Finds the best straight line through your data points.</p>
<p><strong>Mathematical Formula</strong>: </p>
<pre><code>≈∑ = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çôx‚Çô

Where:
≈∑ = predicted value
Œ≤‚ÇÄ = intercept (bias)
Œ≤‚ÇÅ, Œ≤‚ÇÇ, ..., Œ≤‚Çô = coefficients (weights)
x‚ÇÅ, x‚ÇÇ, ..., x‚Çô = feature values
</code></pre>
<p>Simple form: <code>y = mx + b</code>    </p>
<ul>
<li>Simple and interpretable</li>
<li>Assumes linear relationship between features and target</li>
</ul>
<p><img alt="Linear Regression Diagram" src="../../assets/image2.png" /></p>
<p><strong>Strengths</strong>:  </p>
<ul>
<li>Fast to train</li>
<li>Easy to interpret</li>
<li>Works well with linear relationships</li>
</ul>
<p><strong>Weaknesses</strong>:  </p>
<ul>
<li>Cannot capture complex non-linear patterns</li>
<li>Sensitive to outliers - basically those values that are much out of range when compared to normal values</li>
</ul>
<p><strong>Use cases :</strong>  </p>
<ul>
<li>Predicting house prices based on area, location, etc.  </li>
<li>Estimating sales revenue from advertising spend.  </li>
<li>Forecasting demand or performance metrics. </li>
</ul>
<hr />
<h3 id="62-decision-tree-regressor">6.2. Decision Tree Regressor<a class="headerlink" href="#62-decision-tree-regressor" title="Permanent link">&para;</a></h3>
<p><strong>How it works</strong>: Creates a tree of yes/no questions to make predictions.</p>
<p><strong>Example</strong>:</p>
<pre><code>Is size &gt; 2000 sq ft?
  ‚îú‚îÄ Yes ‚Üí Is location = downtown?
  ‚îÇ         ‚îú‚îÄ Yes ‚Üí Predict $500k
  ‚îÇ         ‚îî‚îÄ No ‚Üí Predict $350k
  ‚îî‚îÄ No ‚Üí Predict $250k
</code></pre>
<p><img alt="Decision Tree Diagram" src="../../assets/image3.png" /></p>
<p><strong>Mathematical Formula :</strong></p>
<pre><code>Prediction at leaf node = (1/n) Œ£·µ¢‚Çå‚ÇÅ‚Åø y·µ¢

Where:
n = number of samples in the leaf
y·µ¢ = actual values in the leaf
(Takes the mean of training samples that reach that leaf)

Split criterion (MSE):
MSE = (1/n) Œ£·µ¢‚Çå‚ÇÅ‚Åø (y·µ¢ - ≈∑)¬≤
</code></pre>
<p><strong>Strengths</strong>:  </p>
<ul>
<li>Handles non-linear relationships</li>
<li>Easy to visualize and understand</li>
<li>No feature scaling needed</li>
</ul>
<p><strong>Weaknesses</strong>:  </p>
<ul>
<li>Can overfit easily</li>
<li>Sensitive to small data changes</li>
<li>May create overly complex trees</li>
</ul>
<p><strong>Use cases :</strong>  </p>
<ul>
<li>Predicting sales based on season, location, and marketing.  </li>
<li>Modeling complex, non-linear data patterns.  </li>
</ul>
<hr />
<h3 id="63-random-forest-regressor">6.3. Random Forest Regressor<a class="headerlink" href="#63-random-forest-regressor" title="Permanent link">&para;</a></h3>
<p><strong>How it works</strong>: Creates many decision trees and averages their predictions.</p>
<p><strong>Think of it as</strong>: A committee of experts voting on the answer
- Each tree sees slightly different data
- Final prediction = average of all trees
- Reduces overfitting compared to single tree</p>
<p><img alt="Random Forest Regressor Diagram" src="../../assets/image4.png" /></p>
<p><strong>Mathematical Formula :</strong></p>
<pre><code>≈∑ = (1/T) Œ£‚Çú‚Çå‚ÇÅ·µÄ h‚Çú(x)

Where:
T = number of trees in the forest
h‚Çú(x) = prediction from tree t
≈∑ = final prediction (average of all trees)
</code></pre>
<p><strong>Strengths</strong>:  </p>
<ul>
<li>More accurate than single decision tree</li>
<li>Handles complex relationships</li>
<li>Reduces overfitting</li>
<li>Shows feature importance</li>
</ul>
<p><strong>Weaknesses</strong>:  </p>
<ul>
<li>Slower to train</li>
<li>Less interpretable</li>
<li>Requires more memory</li>
</ul>
<p><strong>Use Cases :</strong>  </p>
<ul>
<li>Predicting house prices, insurance claim amounts.  </li>
<li>Forecasting demand or energy consumption. </li>
</ul>
<hr />
<h3 id="64-k-nearest-neighbors-knn-regressor">6.4. K-Nearest Neighbors (KNN) Regressor<a class="headerlink" href="#64-k-nearest-neighbors-knn-regressor" title="Permanent link">&para;</a></h3>
<p><strong>How it works</strong>: Predicts based on the K closest training examples.</p>
<p><strong>Example</strong> (K=5):
- Find 5 nearest houses to your property
- Average their prices
- That's your prediction</p>
<p><strong>Mathematical Formula :</strong></p>
<pre><code>≈∑ = (1/K) Œ£·µ¢‚Çå‚ÇÅ·¥∑ y·µ¢

Where:
K = number of nearest neighbors
y·µ¢ = value of i-th nearest neighbor

Distance (Euclidean):
d(x, x·µ¢) = ‚àö(Œ£‚±º‚Çå‚ÇÅ‚Åø (x‚±º - x·µ¢‚±º)¬≤)
</code></pre>
<p><img alt="KNN Regressor Diagram" src="../../assets/image6.png" /></p>
<p><strong>Strengths</strong>:  </p>
<ul>
<li>Simple to understand</li>
<li>No training phase (lazy learning)</li>
<li>Naturally handles non-linear patterns</li>
</ul>
<p><strong>Weaknesses</strong>:  </p>
<ul>
<li>Slow predictions on large datasets</li>
<li>Needs feature scaling</li>
<li>Sensitive to irrelevant features</li>
</ul>
<p><strong>Use Cases :</strong>  </p>
<ul>
<li>Estimating house rent based on nearby similar properties.  </li>
<li>Predicting temperature using data from nearby weather stations.</li>
</ul>
<hr />
<h2 id="7-classification-models">7. Classification Models<a class="headerlink" href="#7-classification-models" title="Permanent link">&para;</a></h2>
<p>Classification predicts <strong>categories/classes</strong> (e.g., spam/not spam, disease/healthy, high/medium/low price).</p>
<h3 id="71-logistic-regression">7.1. Logistic Regression<a class="headerlink" href="#71-logistic-regression" title="Permanent link">&para;</a></h3>
<p><strong>How it works</strong>: Despite the name, it's for classification! Predicts probability of belonging to a class.</p>
<p><strong>Example</strong>: Predicting if house is "expensive" or "affordable"</p>
<pre><code>Probability = 1 / (1 + e^(-score))
If probability &gt; 0.5 ‚Üí Expensive
If probability ‚â§ 0.5 ‚Üí Affordable
</code></pre>
<p><strong>Mathematical Formula :</strong></p>
<pre><code>P(y=1|x) = 1 / (1 + e^(-z))

Where:
z = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çôx‚Çô
P(y=1|x) = probability of class 1
e = Euler's number (‚âà2.718)

Decision: If P(y=1|x) &gt; 0.5 ‚Üí Class 1
          If P(y=1|x) ‚â§ 0.5 ‚Üí Class 0
</code></pre>
<p><img alt="Logistic Regression Diagram" src="../../assets/image7.png" /></p>
<p><strong>Strengths</strong>:  </p>
<ul>
<li>Fast and efficient</li>
<li>Provides probability scores</li>
<li>Easy to interpret</li>
</ul>
<p><strong>Weaknesses</strong>:  </p>
<ul>
<li>Assumes linear decision boundary</li>
<li>Not effective for complex relationships</li>
</ul>
<p><strong>When to use</strong>: Binary classification with linearly separable data</p>
<hr />
<h3 id="72-decision-tree-classifier">7.2. Decision Tree Classifier<a class="headerlink" href="#72-decision-tree-classifier" title="Permanent link">&para;</a></h3>
<p><strong>How it works</strong>: Same tree structure as regression, but predicts categories.</p>
<p><strong>Example</strong>:</p>
<pre><code>Is size &gt; 2000 sq ft?
  ‚îú‚îÄ Yes ‚Üí Is location = downtown?
  ‚îÇ         ‚îú‚îÄ Yes ‚Üí Class: Luxury
  ‚îÇ         ‚îî‚îÄ No ‚Üí Class: Standard
  ‚îî‚îÄ No ‚Üí Class: Budget
</code></pre>
<p><strong>Mathematical Formula :</strong></p>
<pre><code>Gini Impurity = 1 - Œ£·µ¢‚Çå‚ÇÅ·∂ú p·µ¢¬≤

Where:
c = number of classes
p·µ¢ = proportion of class i in node

Entropy (alternative):
H = -Œ£·µ¢‚Çå‚ÇÅ·∂ú p·µ¢ log‚ÇÇ(p·µ¢)

(Tree splits to minimize impurity)
</code></pre>
<p><img alt="Decision Tree Classifier" src="../../assets/image8.png" /></p>
<p><strong>Strengths</strong>:  </p>
<ul>
<li>Handles non-linear boundaries</li>
<li>Interpretable</li>
<li>Works with categorical data</li>
</ul>
<p><strong>Weaknesses</strong>:  </p>
<ul>
<li>Overfits easily</li>
<li>Unstable with small data changes</li>
</ul>
<p><strong>When to use</strong>: When you need interpretability and have categorical data</p>
<hr />
<h3 id="73-random-forest-classifier">7.3. Random Forest Classifier<a class="headerlink" href="#73-random-forest-classifier" title="Permanent link">&para;</a></h3>
<p><strong>How it works</strong>: Ensemble of decision trees voting on the class.</p>
<p><strong>Voting Example</strong> (5 trees):  </p>
<ul>
<li>Tree 1: Luxury</li>
<li>Tree 2: Standard</li>
<li>Tree 3: Luxury</li>
<li>Tree 4: Luxury</li>
<li>Tree 5: Standard</li>
<li><strong>Final Prediction</strong>: Luxury (majority vote: 3/5)</li>
</ul>
<p><strong>Mathematical Formula :</strong></p>
<pre><code>≈∑ = mode{h‚ÇÅ(x), h‚ÇÇ(x), ..., h‚Çú(x)}

Where:
T = number of trees
h‚Çú(x) = prediction from tree t
mode = most frequent class (majority vote)

For probabilities:
P(class=c|x) = (1/T) Œ£‚Çú‚Çå‚ÇÅ·µÄ I(h‚Çú(x) = c)
</code></pre>
<p><img alt="Random Forest Classifier" src="../../assets/image9.png" /></p>
<p><strong>Strengths</strong>:  </p>
<ul>
<li>High accuracy</li>
<li>Reduces overfitting</li>
<li>Shows feature importance</li>
<li>Handles imbalanced data well</li>
</ul>
<p><strong>Weaknesses</strong>:  </p>
<ul>
<li>Slower than single tree</li>
<li>Less interpretable</li>
<li>More memory intensive</li>
</ul>
<p><strong>When to use</strong>: When accuracy is priority and you have sufficient data</p>
<hr />
<h3 id="74-k-nearest-neighbors-knn-classifier">7.4. K-Nearest Neighbors (KNN) Classifier<a class="headerlink" href="#74-k-nearest-neighbors-knn-classifier" title="Permanent link">&para;</a></h3>
<p><strong>How it works</strong>: Assigns class based on K nearest neighbors' majority vote.</p>
<p><strong>Example</strong> (K=5):  </p>
<ul>
<li>Find 5 nearest houses</li>
<li>3 are "Luxury", 2 are "Standard"</li>
<li>Predict: "Luxury" (majority)</li>
</ul>
<p><strong>Mathematical Formula :</strong></p>
<pre><code>≈∑ = mode{y‚ÇÅ, y‚ÇÇ, ..., y‚Çñ}

Where:
K = number of nearest neighbors
y·µ¢ = class of i-th nearest neighbor
mode = most frequent class

Distance (Euclidean):
d(x, x·µ¢) = ‚àö(Œ£‚±º‚Çå‚ÇÅ‚Åø (x‚±º - x·µ¢‚±º)¬≤)
</code></pre>
<p><img alt="KNN Classifier" src="../../assets/image11.png" /></p>
<p><strong>Strengths</strong>:  </p>
<ul>
<li>Simple and intuitive</li>
<li>No training needed</li>
<li>Naturally handles multi-class</li>
</ul>
<p><strong>Weaknesses</strong>:  </p>
<ul>
<li>Slow for large datasets</li>
<li>Sensitive to feature scaling</li>
<li>Curse of dimensionality</li>
</ul>
<p><strong>When to use</strong>: Small to medium datasets with good feature engineering</p>
<hr />
<h2 id="8-evaluation-metrics">8. Evaluation Metrics<a class="headerlink" href="#8-evaluation-metrics" title="Permanent link">&para;</a></h2>
<h3 id="section-81-regression-metrics">Section 8.1 : Regression Metrics<a class="headerlink" href="#section-81-regression-metrics" title="Permanent link">&para;</a></h3>
<p><img alt="Regression Metrics" src="../../assets/image17.png" />  </p>
<hr />
<h4 id="811-mean-squared-error-mse">8.1.1. Mean Squared Error (MSE)<a class="headerlink" href="#811-mean-squared-error-mse" title="Permanent link">&para;</a></h4>
<p><strong>Formula</strong>: Average of squared differences between predictions and actual values<br />
<code>MSE = (1/n) * Œ£ (y·µ¢ - ≈∑·µ¢)¬≤</code></p>
<p><strong>Interpretation</strong>:  </p>
<ul>
<li>Lower is better</li>
<li>Heavily penalizes large errors</li>
<li>Units are squared (e.g., dollars¬≤)</li>
</ul>
<p><strong>Example</strong>:   </p>
<ul>
<li>Actual: $300k, Predicted: $310k ‚Üí Error¬≤: (10k)¬≤ = 100M</li>
<li>Actual: $300k, Predicted: $320k ‚Üí Error¬≤: (20k)¬≤ = 400M</li>
<li>MSE = (100M + 400M) / 2 = 250M</li>
</ul>
<p><strong>Common Use Cases :</strong></p>
<ul>
<li>
<p><strong>Training neural networks:</strong> Used as a loss function because it's differentiable and penalizes large errors  </p>
</li>
<li>
<p><strong>Quality control:</strong> When large deviations are particularly costly or dangerous  </p>
</li>
<li>
<p><strong>Financial forecasting:</strong> Where overestimating or underestimating by large amounts has severe consequences  </p>
</li>
</ul>
<hr />
<h4 id="812-root-mean-squared-error-rmse">8.1.2. Root Mean Squared Error (RMSE)<a class="headerlink" href="#812-root-mean-squared-error-rmse" title="Permanent link">&para;</a></h4>
<p><strong>Formula</strong>: Square root of MSE<br />
<code>RMSE = ‚àö[ (1/n) * Œ£ (y·µ¢ - ≈∑·µ¢)¬≤ ]</code></p>
<p><strong>Interpretation</strong>:  </p>
<ul>
<li>Lower is better</li>
<li>Same units as target (dollars, not dollars¬≤)</li>
<li>More interpretable than MSE</li>
</ul>
<p><strong>Example</strong>:  </p>
<ul>
<li>From above, MSE = 250M  </li>
<li>RMSE = ‚àö250M ‚âà 15.8k</li>
</ul>
<p><strong>Common Use Cases :</strong></p>
<ul>
<li>
<p><strong>Real estate price prediction:</strong> Easy to interpret ("model is off by $15.8k on average")  </p>
</li>
<li>
<p><strong>Weather forecasting:</strong> Temperature predictions where errors need to be in degrees, not degrees¬≤  </p>
</li>
<li>
<p><strong>Sales forecasting:</strong> When stakeholders need to understand prediction error in actual sales units</p>
</li>
</ul>
<hr />
<h4 id="813-mean-absolute-error-mae">8.1.3. Mean Absolute Error (MAE)<a class="headerlink" href="#813-mean-absolute-error-mae" title="Permanent link">&para;</a></h4>
<p><strong>Formula</strong>: Average of absolute differences<br />
<code>MAE = (1/n) * Œ£ |y·µ¢ - ≈∑·µ¢|</code></p>
<p><strong>Interpretation</strong>:  </p>
<ul>
<li>Lower is better</li>
<li>Less sensitive to outliers than RMSE</li>
<li>Direct average error</li>
</ul>
<p><strong>Example:</strong>    </p>
<ul>
<li>Actual: $300k, Predicted: $310k ‚Üí |Error| = 10k  </li>
<li>Actual: $300k, Predicted: $320k ‚Üí |Error| = 20k  </li>
<li>MAE = (10k + 20k) / 2 = 15k</li>
</ul>
<p><strong>Common Use Cases :</strong>  </p>
<ul>
<li>
<p><strong>Energy consumption forecasting:</strong> Where extreme values (holidays, events) shouldn't dominate the metric  </p>
</li>
<li>
<p><strong>Customer lifetime value prediction:</strong> When a few high-value customers shouldn't distort performance  </p>
</li>
<li>
<p><strong>Budget planning:</strong> Where you need realistic average deviations for resource allocation</p>
</li>
</ul>
<hr />
<h4 id="814-r2-score-r-squared">8.1.4. R¬≤ Score (R-Squared)<a class="headerlink" href="#814-r2-score-r-squared" title="Permanent link">&para;</a></h4>
<p><strong>Formula</strong>: 1 - (Sum of Squared Residuals / Total Sum of Squares)<br />
<code>R¬≤ = 1 - [ Œ£ (y·µ¢ - ≈∑·µ¢)¬≤ / Œ£ (y·µ¢ - »≥)¬≤ ]</code></p>
<p><strong>Interpretation</strong>:  </p>
<ul>
<li>Range: -‚àû to 1.0</li>
<li>1.0 = Perfect predictions</li>
<li>0.0 = Model no better than predicting mean</li>
<li>&lt; 0 = Model worse than predicting mean</li>
</ul>
<p><strong>Example:</strong>  </p>
<ul>
<li>Total variance (Œ£(y·µ¢ - »≥)¬≤) = 1000M  </li>
<li>Residual variance (Œ£(y·µ¢ - ≈∑·µ¢)¬≤) = 250M  </li>
<li>R¬≤ = 1 - (250 / 1000) = 0.75 ‚Üí Model explains 75% of variance</li>
</ul>
<p><strong>Common Use Cases :</strong>  </p>
<ul>
<li>
<p><strong>Scientific research:</strong> Reporting how well your model explains the phenomenon  </p>
</li>
<li>
<p><strong>Marketing analytics:</strong> Understanding how much of sales variance is explained by campaigns vs. other factors  </p>
</li>
<li>
<p><strong>Academic/reporting contexts:</strong> When stakeholders need a single, intuitive performance metric</p>
</li>
</ul>
<hr />
<h3 id="82-classification-metrics">8.2. Classification Metrics<a class="headerlink" href="#82-classification-metrics" title="Permanent link">&para;</a></h3>
<p>Let us assume we have:</p>
<table>
<thead>
<tr>
<th>Actual</th>
<th>Predicted</th>
</tr>
</thead>
<tbody>
<tr>
<td>Positive (1)</td>
<td>Positive (1)</td>
</tr>
<tr>
<td>Negative (0)</td>
<td>Positive (1)</td>
</tr>
<tr>
<td>Positive (1)</td>
<td>Negative (0)</td>
</tr>
<tr>
<td>Negative (0)</td>
<td>Negative (0)</td>
</tr>
</tbody>
</table>
<p>So:<br />
TP = 1, TN = 1, FP = 1, FN = 1</p>
<p><img alt="Classification Metrics" src="../../assets/image18.png" />  </p>
<hr />
<h4 id="821-accuracy">8.2.1. Accuracy<a class="headerlink" href="#821-accuracy" title="Permanent link">&para;</a></h4>
<p><strong>Formula</strong>: (Correct Predictions) / (Total Predictions)<br />
<code>Accuracy = (TP + TN) / (TP + TN + FP + FN)</code></p>
<p><strong>Example</strong>:
Accuracy = (1 + 1) / (1 + 1 + 1 + 1) = 0.5 ‚Üí <strong>50% accuracy</strong></p>
<p><strong>Limitation</strong>: Misleading with imbalanced classes</p>
<p><strong>Common Use Cases :</strong>  </p>
<ul>
<li>
<p><strong>Quality assessment:</strong> Product defect detection when defects and non-defects are roughly equal  </p>
</li>
<li>
<p><strong>Initial model evaluation:</strong> Quick baseline metric before diving into detailed analysis  </p>
</li>
<li>
<p><strong>Avoid for:</strong> Fraud detection, disease diagnosis, or any imbalanced dataset (accuracy paradox)</p>
</li>
</ul>
<hr />
<h4 id="822-confusion-matrix">8.2.2. Confusion Matrix<a class="headerlink" href="#822-confusion-matrix" title="Permanent link">&para;</a></h4>
<p>Compares predictions vs actual:</p>
<pre><code>                Predicted
              No    Yes
Actual  No   [TN]  [FP]
        Yes  [FN]  [TP]
</code></pre>
<ul>
<li><strong>TP</strong>: True Positives (correctly predicted Yes)</li>
<li><strong>TN</strong>: True Negatives (correctly predicted No)</li>
<li><strong>FP</strong>: False Positives (predicted Yes, actually No)</li>
<li><strong>FN</strong>: False Negatives (predicted No, actually Yes)</li>
</ul>
<p><strong>Common Use Cases :</strong>  </p>
<ul>
<li>
<p><strong>Medical diagnosis:</strong> Understanding both false alarms (FP) and missed cases (FN)  </p>
</li>
<li>
<p><strong>Spam filtering:</strong> Seeing how many legitimate emails are caught (FP) vs. spam that gets through (FN)</p>
</li>
</ul>
<hr />
<h4 id="823-precision">8.2.3. Precision<a class="headerlink" href="#823-precision" title="Permanent link">&para;</a></h4>
<p><strong>Formula</strong>: <br />
<code>TP / (TP + FP)</code></p>
<p><strong>Meaning</strong>: "Of all positive predictions, how many were correct?"</p>
<p><strong>Example</strong>:
 = 1 / (1 + 1) = 0.5 ‚Üí <strong>50% of predicted positives are correct</strong></p>
<p><strong>Common Use Cases :</strong>  </p>
<ul>
<li>
<p><strong>Product recommendations:</strong> Only recommend products you're confident users will like  </p>
</li>
<li>
<p><strong>Marketing campaign targeting:</strong> When contacting customers has a cost, ensure targets are relevant </p>
</li>
<li>
<p><strong>Legal document review:</strong> When reviewing flagged documents is expensive, minimize false flags</p>
</li>
</ul>
<hr />
<h4 id="824-recall-sensitivity">8.2.4. Recall (Sensitivity)<a class="headerlink" href="#824-recall-sensitivity" title="Permanent link">&para;</a></h4>
<p><strong>Formula</strong>: <br />
<code>TP / (TP + FN)</code></p>
<p><strong>Meaning</strong>: "Of all actual positives, how many did we catch?"</p>
<p><strong>Example :</strong>
= 1 / (1 + 1) = 0.5 ‚Üí <strong>50% of actual positives identified</strong></p>
<p><strong>Common Use Cases :</strong>  </p>
<ul>
<li>
<p><strong>Fraud detection:</strong> Better to flag suspicious transactions for review than miss actual fraud  </p>
</li>
<li>
<p><strong>Security systems:</strong> Airport security, intrusion detection where missing threats is catastrophic</p>
</li>
</ul>
<hr />
<h4 id="825-f1-score">8.2.5. F1-Score<a class="headerlink" href="#825-f1-score" title="Permanent link">&para;</a></h4>
<p><strong>Formula</strong>: <br />
<code>F1 = 2 * (Precision * Recall) / (Precision + Recall)</code></p>
<p><strong>Meaning</strong>: Harmonic mean of precision and recall</p>
<p><strong>Example :</strong>
F1 = 2 * (0.5 * 0.5) / (0.5 + 0.5) = 0.5</p>
<p><strong>When to use</strong>: Balances precision and recall, especially with imbalanced data</p>
<p><strong>Common Use Cases :</strong>  </p>
<ul>
<li>
<p><strong>Medical diagnosis with cost considerations:</strong> Balancing false alarms with missed diagnoses  </p>
</li>
<li>
<p><strong>Model comparison:</strong> Single metric for comparing models when both precision and recall matter</p>
</li>
</ul>
<hr />
<h2 id="9-model-comparison-regression-results">9. Model Comparison (Regression Results)<a class="headerlink" href="#9-model-comparison-regression-results" title="Permanent link">&para;</a></h2>
<h3 id="91-regression-performance-ranking">9.1. Regression Performance Ranking<a class="headerlink" href="#91-regression-performance-ranking" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Rank</th>
<th>Model</th>
<th>R¬≤ Score</th>
<th>RMSE</th>
<th>MAE</th>
</tr>
</thead>
<tbody>
<tr>
<td>ü•á 1</td>
<td>Linear Regression</td>
<td>0.7904</td>
<td>30.79</td>
<td>9.95</td>
</tr>
<tr>
<td>ü•à 2</td>
<td>Random Forest</td>
<td>0.7375</td>
<td>34.45</td>
<td>1.77</td>
</tr>
<tr>
<td>ü•â 3</td>
<td>KNN</td>
<td>0.6585</td>
<td>39.29</td>
<td>1.91</td>
</tr>
<tr>
<td>4</td>
<td>Decision Tree</td>
<td>0.6268</td>
<td>41.08</td>
<td>3.14</td>
</tr>
</tbody>
</table>
<h3 id="92-key-observations">9.2. Key Observations<a class="headerlink" href="#92-key-observations" title="Permanent link">&para;</a></h3>
<p><strong>Linear Regression wins because</strong>:  </p>
<ul>
<li>‚úÖ Highest R¬≤ score (79.04%)  </li>
<li>‚úÖ Lowest RMSE (best average error)  </li>
<li>‚úÖ Fast training and prediction  </li>
<li>‚úÖ Easy to interpret  </li>
</ul>
<p><strong>Interesting finding</strong>: Despite lower MAE, Random Forest has better overall performance metrics than simpler models.</p>
<hr />
<h2 id="10-model-comparison-classification-results">10. Model Comparison (Classification Results)<a class="headerlink" href="#10-model-comparison-classification-results" title="Permanent link">&para;</a></h2>
<h3 id="101-classification-performance-ranking">10.1. Classification Performance Ranking<a class="headerlink" href="#101-classification-performance-ranking" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>Accuracy</th>
<th>Precision</th>
<th>Recall</th>
<th>F1 Score</th>
</tr>
</thead>
<tbody>
<tr>
<td>Logistic Regression</td>
<td>0.9231</td>
<td>0.9479</td>
<td>0.9231</td>
<td>0.9271</td>
</tr>
<tr>
<td>Decision Tree</td>
<td>1.0000</td>
<td>1.0000</td>
<td>1.0000</td>
<td>1.0000</td>
</tr>
<tr>
<td>Random Forest</td>
<td>1.0000</td>
<td>1.0000</td>
<td>1.0000</td>
<td>1.0000</td>
</tr>
<tr>
<td>KNN</td>
<td>0.6410</td>
<td>0.6282</td>
<td>0.6410</td>
<td>0.6197</td>
</tr>
</tbody>
</table>
<h3 id="102-confusion-matrix-for-all-models">10.2. Confusion Matrix for all models<a class="headerlink" href="#102-confusion-matrix-for-all-models" title="Permanent link">&para;</a></h3>
<p><img alt="Confusion Matrix for all Models" src="../../assets/image16.png" /></p>
<h3 id="103-key-observations">10.3. Key Observations<a class="headerlink" href="#103-key-observations" title="Permanent link">&para;</a></h3>
<p>üèÜ <strong>BEST CLASSIFICATION MODELS</strong></p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Accuracy</th>
<th>Precision</th>
<th>Recall</th>
<th>F1 Score</th>
</tr>
</thead>
<tbody>
<tr>
<td>Decision Tree</td>
<td>1.0</td>
<td>1.0</td>
<td>1.0</td>
<td>1.0</td>
</tr>
<tr>
<td>Random Forest</td>
<td>1.0</td>
<td>1.0</td>
<td>1.0</td>
<td>1.0</td>
</tr>
</tbody>
</table>
<p><strong>Decision Tree &amp; Random Forest win because:</strong>  </p>
<ul>
<li>‚úÖ Perfect test accuracy on this dataset</li>
<li>‚úÖ Can capture complex, non-linear relationships</li>
<li>‚úÖ Handle both categorical and numerical features naturally</li>
<li>‚úÖ Robust and flexible for small datasets</li>
</ul>
<hr />
<h2 id="11-general-ml-best-practices">11. General ML Best Practices<a class="headerlink" href="#11-general-ml-best-practices" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p><strong>Always split your data</strong></p>
<ul>
<li>Train-test split prevents overfitting</li>
<li>Use cross-validation for robust evaluation</li>
</ul>
</li>
<li>
<p><strong>Try multiple models</strong></p>
<ul>
<li>Different models work better for different data</li>
<li>No "one size fits all" solution</li>
</ul>
</li>
<li>
<p><strong>Understand your metrics</strong></p>
<ul>
<li>R¬≤ for overall model fit</li>
<li>RMSE for average prediction error</li>
<li>MAE for median error magnitude</li>
</ul>
</li>
<li>
<p><strong>Consider the business context</strong></p>
<ul>
<li>Is $31k error acceptable for your use case?</li>
<li>Sometimes a simple, interpretable model is better than a complex one</li>
</ul>
</li>
</ul>
<hr />
<h2 id="12-summary">12. Summary<a class="headerlink" href="#12-summary" title="Permanent link">&para;</a></h2>
<p><strong>You've learned</strong>:</p>
<ul>
<li>‚úÖ Train-test split methodology</li>
<li>‚úÖ 5 regression algorithms</li>
<li>‚úÖ 6 classification algorithms </li>
<li>‚úÖ Multiple evaluation metrics</li>
<li>‚úÖ Model comparison techniques</li>
</ul>
<hr />
<p><strong>Remember</strong>: 
The best model isn't always the most complex one.   <br />
Choose based on:  </p>
<ul>
<li>Performance on test data</li>
<li>Interpretability needs</li>
<li>Computational resources</li>
<li>Business requirements</li>
</ul>
<hr />
<p><em>Created for ML Workshop Day 2 | Happy Learning! üéì</em></p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024 - ACM BITS Pilani Dubai Campus
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://instagram.com/acmbpdc" target="_blank" rel="noopener" title="instagram.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M224.3 141a115 115 0 1 0-.6 230 115 115 0 1 0 .6-230m-.6 40.4a74.6 74.6 0 1 1 .6 149.2 74.6 74.6 0 1 1-.6-149.2m93.4-45.1a26.8 26.8 0 1 1 53.6 0 26.8 26.8 0 1 1-53.6 0m129.7 27.2c-1.7-35.9-9.9-67.7-36.2-93.9-26.2-26.2-58-34.4-93.9-36.2-37-2.1-147.9-2.1-184.9 0-35.8 1.7-67.6 9.9-93.9 36.1s-34.4 58-36.2 93.9c-2.1 37-2.1 147.9 0 184.9 1.7 35.9 9.9 67.7 36.2 93.9s58 34.4 93.9 36.2c37 2.1 147.9 2.1 184.9 0 35.9-1.7 67.7-9.9 93.9-36.2 26.2-26.2 34.4-58 36.2-93.9 2.1-37 2.1-147.8 0-184.8M399 388c-7.8 19.6-22.9 34.7-42.6 42.6-29.5 11.7-99.5 9-132.1 9s-102.7 2.6-132.1-9c-19.6-7.8-34.7-22.9-42.6-42.6-11.7-29.5-9-99.5-9-132.1s-2.6-102.7 9-132.1c7.8-19.6 22.9-34.7 42.6-42.6 29.5-11.7 99.5-9 132.1-9s102.7-2.6 132.1 9c19.6 7.8 34.7 22.9 42.6 42.6 11.7 29.5 9 99.5 9 132.1s2.7 102.7-9 132.1"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/acmbpdc" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://discord.gg/DYQdxquYwP" target="_blank" rel="noopener" title="discord.gg" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M492.5 69.8c-.2-.3-.4-.6-.8-.7-38.1-17.5-78.4-30-119.7-37.1-.4-.1-.8 0-1.1.1s-.6.4-.8.8c-5.5 9.9-10.5 20.2-14.9 30.6-44.6-6.8-89.9-6.8-134.4 0-4.5-10.5-9.5-20.7-15.1-30.6-.2-.3-.5-.6-.8-.8s-.7-.2-1.1-.2C162.5 39 122.2 51.5 84.1 69c-.3.1-.6.4-.8.7C7.1 183.5-13.8 294.6-3.6 404.2c0 .3.1.5.2.8s.3.4.5.6c44.4 32.9 94 58 146.8 74.2.4.1.8.1 1.1 0s.7-.4.9-.7c11.3-15.4 21.4-31.8 30-48.8.1-.2.2-.5.2-.8s0-.5-.1-.8-.2-.5-.4-.6-.4-.3-.7-.4c-15.8-6.1-31.2-13.4-45.9-21.9-.3-.2-.5-.4-.7-.6s-.3-.6-.3-.9 0-.6.2-.9.3-.5.6-.7c3.1-2.3 6.2-4.7 9.1-7.1.3-.2.6-.4.9-.4s.7 0 1 .1c96.2 43.9 200.4 43.9 295.5 0 .3-.1.7-.2 1-.2s.7.2.9.4c2.9 2.4 6 4.9 9.1 7.2.2.2.4.4.6.7s.2.6.2.9-.1.6-.3.9-.4.5-.6.6c-14.7 8.6-30 15.9-45.9 21.8-.2.1-.5.2-.7.4s-.3.4-.4.7-.1.5-.1.8.1.5.2.8c8.8 17 18.8 33.3 30 48.8.2.3.6.6.9.7s.8.1 1.1 0c52.9-16.2 102.6-41.3 147.1-74.2.2-.2.4-.4.5-.6s.2-.5.2-.8c12.3-126.8-20.5-236.9-86.9-334.5zm-302 267.7c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.4 59.2-52.8 59.2m195.4 0c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.2 59.2-52.8 59.2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "header.autohide"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>