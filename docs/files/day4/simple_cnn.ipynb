{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af159ee",
   "metadata": {},
   "source": [
    "First, we start off with importing all the models required, for this particular workshop, we will be using pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ba34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40035434",
   "metadata": {},
   "source": [
    "The above cell is used to detect if there's CUDA functionality, basically if you have an Nvidia GPU, you can use that for model training, instead of using CPU power completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da7e4f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# âœ… Device configuration (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e743d12",
   "metadata": {},
   "source": [
    "Now, the model we will be focusing on is called Resnet-50. For resnet-50, the input required is 224 x 224 x 3, but then the image size of the dataset is 28 x 28 x 1. So, for resnet-50, we will need to transform to 224 x 224, and now, its only 1 channel present in the image, but then the input taken by the model is 3 channels, so we use the greyscale function to convert to 3 channels, and then we convert images to tensor values, and we normalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b03de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                         (0.229, 0.224, 0.225))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa283ea",
   "metadata": {},
   "source": [
    "This is to load the MNIST dataset (which is a digit classification dataset, has multiple hand written images from 0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06227f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f02933c",
   "metadata": {},
   "source": [
    "This is to load the resnet-18 model, and the resnet-18 model initially outputs 1000 classes, but then we only need 10 (0-9), so we mention 10 as well to output only 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a729877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=None)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e564a8",
   "metadata": {},
   "source": [
    "This initializes the loss and optimizer required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Loss & optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb95c1c",
   "metadata": {},
   "source": [
    "Initializes the number of epochs ( the number of times the model trains ), and total images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57b14cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "total_steps = len(train_loader)\n",
    "total_images = len(train_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9c553d",
   "metadata": {},
   "source": [
    "Training with log information as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7169137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Print progress\n",
    "        processed = (batch_idx + 1) * imgs.size(0)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | \"\n",
    "              f\"Step [{batch_idx+1}/{total_steps}] | \"\n",
    "              f\"Images: {processed}/{total_images} | \"\n",
    "              f\"Loss: {loss.item():.4f}\", end=\"\\r\")\n",
    "\n",
    "    print(f\"\\nâœ… Epoch [{epoch+1}/{num_epochs}] completed. \"\n",
    "          f\"Average Loss: {running_loss / total_steps:.4f}\\n\")\n",
    "\n",
    "print(\"ðŸŽ‰ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7466c99a",
   "metadata": {},
   "source": [
    "To visualize 15 predictions, using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e825a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'imgs' and 'outputs' are from your last training batch\n",
    "# Get predicted class\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# âœ… Denormalize images (since you used ImageNet normalization)\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "\n",
    "# Move tensors to CPU for plotting\n",
    "imgs_cpu = imgs.detach().cpu()\n",
    "predicted_cpu = predicted.detach().cpu()\n",
    "\n",
    "# âœ… Denormalize\n",
    "images_denorm = imgs_cpu * std + mean\n",
    "images_denorm = torch.clamp(images_denorm, 0, 1)  # keep pixel range valid\n",
    "\n",
    "# âœ… Plot 15 images with predictions\n",
    "fig, axes = plt.subplots(1, 15, figsize=(15, 3))\n",
    "for i in range(15):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(images_denorm[i].permute(1, 2, 0))  # CÃ—HÃ—W â†’ HÃ—WÃ—C\n",
    "    ax.set_title(f\"Pred: {predicted_cpu[i].item()}\", fontsize=8)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
